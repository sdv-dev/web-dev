{"componentChunkName":"component---src-templates-post-js","path":"/community-feedback-workflow/","result":{"data":{"ghostPost":{"id":"Ghost__Post__609c384488b3f9003e080016","title":"Your Feedback in Action, Part 2: Data Workflow","slug":"community-feedback-workflow","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2021/05/Banner-2-1.png","excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","custom_excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","visibility":"public","created_at_pretty":"12 May, 2021","published_at_pretty":"19 May, 2021","updated_at_pretty":"19 May, 2021","created_at":"2021-05-12T16:19:16.000-04:00","published_at":"2021-05-19T12:52:14.000-04:00","updated_at":"2021-05-19T12:52:14.000-04:00","meta_title":"Improving synthetic data workflows","meta_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","twitter_image":null,"twitter_title":null,"authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"The Synthetic Data Vault (SDV) is a software system that allows users all over\nthe world to input a dataset and generate synthetic data. The SDV was born out\nof academic research at MIT — but in 2018, we open-sourced it, so that people\nall over the world could use it.\n\nSince then, we've been listening carefully to our community's feedback, making\nsure that we address any gaps between theoretical academic research and\npractical use. This article is the second in a multi-part series detailing\nrecent improvements to the SDV that make it work in the real world. Here we'll\ndiscuss how we've amped up the data synthesis workflow. (For our previous\ndiscussion about how we've improved core models, see Part 1\n[http://sdv.dev/blog/community-feedback-models].)\n\nWhat are workflows?\nWe open sourced the SDV not just to let users generate synthetic data, but also\nto allow them use that data to solve real-world problems. Our community taught\nus that actually using the SDV involves a multi-step process — and that\nimproving the system means paying attention to this entire workflow, not just\nthe core machine learning.\n\nAccording to our users, this workflow boils down to a few generalizable steps:\n\n 1. Identifying real datasets that need to be synthesized\n 2. Transforming the datasets into a machine-readable format\n 3. Running the machine learning model\n 4. Synthesizing data according to particular specifications\n 5. Reversing the transformations such that the synthesized data looks like the\n    original\n 6. Evaluating the synthesized data that results\n\nThese steps are illustrated in the diagram below.\n\nThe entire synthetic data workflow involves more than just modeling. Data also\nneeds to be transformed, synthesized, reverse transformed, and evaluated.The key\ninsight from our users was that the application of machine learning models is\nonly one step of a much larger puzzle. When the open source community helped us\nunderstand this, we were able to improve on the SDV software by adding in\ntransformations, synthesizing options, and evaluation tools -- all detailed\nbelow.\n\nTransforming Data\nOne major lesson from our open source community was how messy real-world\ndatasets are compared to those used in academia. Academic datasets often come\npre-sanitized and ready for numerical use. In the real world, however, databases\nare growing and changing constantly, and are often significantly different from\nthe optimal yet theoretical structures used by machine learning researchers.\n\nTwo thorny data types frequently encountered in the real world are datetimes and \nnull values.\n\n * Datetimes can follow many different formats, including YYYY-MM-DD or\n   MM-DD-YY. However, machine learning models accept numerical values only.\n   Usually these are Unix timestamps, defined as the number of seconds that have\n   elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will\n   transform into the number 1609488000.\n * Null values also present a problem for mathematical models when they appear\n   in numerical data. While users can tell models to ignore these values, the\n   presence of a null might actually indicate something important, like a user\n   declining to answer a question. To account for this, the SDV creates a new,\n   binary column to address whether the original value is null.\n\nWhen working with real-world datasets, it's necessary to apply transformations\nbetween real data and machine-readable data. This example transforms datetimes\nand null values.To solve this problem, we introduced a new library called Reversible Data\nTransforms [https://github.com/sdv-dev/RDT] (RDT). The RDT library contains\nnecessary logic for transforming different types of real world data to its\nmachine-ready counterpart — as well as the logic for its reversal, so that a\nsynthetic data user won't know the difference. The RDT is a standalone library\nthat can reach beyond the synthetic data space, helping data scientists and\nacademics across fields to clean their data. Since November 2020, the RDT has\nbeen supported on all major platforms including MacOS, Windows, and Linux.\n\nSynthesizing Data Conditionally\nWhen we first imagined the SDV, we assumed users would simply want to use all\nthe synthetic data generated by the model. However, we soon found that some\nusers have more complex needs, and require more control over the data they\nsynthesize — opening up new possibilities for synthetic data in the process.\n\nFor example, one of our users, an engineer, found a whole new use for SDV. The\nengineer was writing a machine learning classifier on a dataset when they\nnoticed it was unbalanced. Applying any algorithms to this dataset would lead to\nbiased models. The engineer realized that, if used strategically, SDV could\nactually debias the data — if it only generated data with rarer attributes, the\nsynthetic data it created could be combined with the real data to form a fully\nbalanced dataset.\n\nSynthesized data can help remove bias by creating balanced datasets. In this\nexample, synthesizing those rows that only correspond to females creates a\nbalance between males and females.In February of 2021, we added conditional sampling\n[https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling] \nto the SDV to enable this use case. Now, users can specify attributes or values\nthat must be present in the synthesized data. In addition to debiasing datasets,\nusers can use this feature to test hypothetical scenarios.\n\nEvaluating Synthesized Data\nWhen the entire system is working smoothly and outputting synthetic data, users\nstill need to know: Is the data good enough to use? This vital question inspired\nus to add evaluation capabilities to the SDV. In doing so, we faced two key\nchallenges: Defining the metrics, and creating a useful process.\n\nMetrics\n\nNo single metric perfectly captures the different dimensions of synthetic data\nusers may want to evaluate. Some want to preserve a high degree of mathematical\nlikeness, others want to emphasize a particular column for machine learning\npredictions, and still others are more focused on threat models that can\ncompromise privacy. \n\nTo address this, we created a separate library, SDMetrics\n[https://github.com/sdv-dev/SDMetrics], to define evaluation metrics. The\nlibrary now includes a suite of metrics that cover differentiation of synthetic\nand real data, statistical likeness, and privacy.\n\nApplication\n\nRather than apply metrics on an ad-hoc basis, some SDV power users were creating\nmini-workflows to rapidly test out different models, datasets and evaluation\ncriteria in succession. Inspired by their innovation, we created SDGym\n[https://github.com/sdv-dev/SDGym], a system that allows users to input models,\ndatasets and success metrics to build a comprehensive evaluation framework.\n\nThe SDV Software Today\nThe SDV software is continuously evolving based on community feedback. In this\narticle, we discussed improvements to the workflow surrounding synthetic data\ngeneration, including data transformations, sampling methods and evaluation\ntools. Earlier, in Part 1 [https://sdv.dev/blog/community-feedback-models] of\nthis series, we discussed the core synthetic data models themselves. In future\nblog articles, we plan to dig deeper into each of these areas, and to uncover\nnew ones with you.\n\nLike the SDV, this blog is a collaborative effort. Use our Slack\n[https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw] \nto let us know which topics you'd like to hear more about. And as always, use \nGitHub [https://github.com/sdv-dev/SDV] to file technical issues with the\nsystem. Working together, we can make SDV the most trusted, transparent and\ncomprehensive platform for synthetic data generation!\n\nFor other inquiries, please contact info@sdv.dev [ info@sdv.dev].","html":"<p>The Synthetic Data Vault (SDV) is a software system that allows users all over the world to input a dataset and generate synthetic data. The SDV was born out of academic research at MIT — but in 2018, we open-sourced it, so that people all over the world could use it.</p><p>Since then, we've been listening carefully to our community's feedback, making sure that we address any gaps between theoretical academic research and practical use. This article is the second in a multi-part series detailing recent improvements to the SDV that make it work in the real world. Here we'll discuss how we've amped up the data synthesis workflow. (For our previous discussion about how we've improved core models, see <a href=\"http://sdv.dev/blog/community-feedback-models\">Part 1</a>.)</p><h3 id=\"what-are-workflows\">What are workflows?</h3><p>We open sourced the SDV not just to let users generate synthetic data, but also to allow them <em>use</em> that data to solve real-world problems. Our community taught us that actually using the SDV involves a multi-step process — and that improving the system means paying attention to this entire workflow, not just the core machine learning.</p><p>According to our users, this workflow boils down to a few generalizable steps:</p><ol><li>Identifying real datasets that need to be synthesized</li><li>Transforming the datasets into a machine-readable format</li><li>Running the machine learning model</li><li>Synthesizing data according to particular specifications</li><li>Reversing the transformations such that the synthesized data looks like the original</li><li>Evaluating the synthesized data that results</li></ol><p>These steps are illustrated in the diagram below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----1.png\" class=\"kg-image\" alt=\"An illustration of the synthetic data workflow: Transforming data, modeling, synthesizing, reverse transforming, and evaluating.\" loading=\"lazy\" width=\"2000\" height=\"1106\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----1.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/05/Community-Feedback--Part-2----1.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The entire synthetic data workflow involves more than just modeling. Data also needs to be transformed, synthesized, reverse transformed, and evaluated.</figcaption></figure><p>The key insight from our users was that the application of machine learning models is only one step of a much larger puzzle. When the open source community helped us understand this, we were able to improve on the SDV software by adding in transformations, synthesizing options, and evaluation tools -- all detailed below.</p><h3 id=\"transforming-data\">Transforming Data</h3><p>One major lesson from our open source community was how messy real-world datasets are compared to those used in academia. Academic datasets often come pre-sanitized and ready for numerical use. In the real world, however, databases are growing and changing constantly, and are often significantly different from the optimal yet theoretical structures used by machine learning researchers.</p><p>Two thorny data types frequently encountered in the real world are <em>datetimes</em> and <em>null values</em>.</p><ul><li><strong>Datetimes</strong> can follow many different formats, including YYYY-MM-DD or MM-DD-YY. However, machine learning models accept numerical values only. Usually these are Unix timestamps, defined as the number of seconds that have elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will transform into the number 1609488000.</li><li><strong>Null values</strong> also present a problem for mathematical models when they appear in numerical data. While users can tell models to ignore these values, the presence of a null might actually indicate something important, like a user declining to answer a question. To account for this, the SDV creates a new, binary column to address whether the original value is null.</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png\" class=\"kg-image\" alt=\"Two tables showing data in its original and transformed formats. The original format includes a human-readable date column and a weight column that can be null.\" loading=\"lazy\" width=\"2000\" height=\"754\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----2-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----2-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----2-1.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png 2280w\" sizes=\"(min-width: 720px) 720px\"><figcaption>When working with real-world datasets, it's necessary to apply transformations between real data and machine-readable data. This example transforms datetimes and null values.</figcaption></figure><p>To solve this problem, we introduced a new library called <a href=\"https://github.com/sdv-dev/RDT\">Reversible Data Transforms</a> (RDT). The RDT library contains necessary logic for transforming different types of real world data to its machine-ready counterpart — as well as the logic for its reversal, so that a synthetic data user won't know the difference. The RDT is a standalone library that can reach beyond the synthetic data space, helping data scientists and academics across fields to clean their data. Since November 2020, the RDT has been supported on all major platforms including MacOS, Windows, and Linux.</p><h3 id=\"synthesizing-data-conditionally\">Synthesizing Data Conditionally</h3><p>When we first imagined the SDV, we assumed users would simply want to use all the synthetic data generated by the model. However, we soon found that some users have more complex needs, and require more control over the data they synthesize — opening up new possibilities for synthetic data in the process.</p><p>For example, one of our users, an engineer, found a whole new use for SDV. The engineer was writing a machine learning classifier on a dataset when they noticed it was unbalanced. Applying any algorithms to this dataset would lead to biased models. The engineer realized that, if used strategically, SDV could actually debias the data — if it only generated data with rarer attributes, the synthetic data it created could be combined with the real data to form a fully balanced dataset.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png\" class=\"kg-image\" alt=\"Biased data that contains more males, plus synthesized data with only females, combines to form a balanced dataset with both males and females.\" loading=\"lazy\" width=\"1705\" height=\"960\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----3.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----3.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----3.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png 1705w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Synthesized data can help remove bias by creating balanced datasets. In this example, synthesizing those rows that only correspond to females creates a balance between males and females.</figcaption></figure><p>In February of 2021, we added <a href=\"https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling\">conditional sampling</a> to the SDV to enable this use case. Now, users can specify attributes or values that must be present in the synthesized data. In addition to debiasing datasets, users can use this feature to test hypothetical scenarios.</p><h3 id=\"evaluating-synthesized-data\">Evaluating Synthesized Data</h3><p>When the entire system is working smoothly and outputting synthetic data, users still need to know: Is the data good enough to use? This vital question inspired us to add evaluation capabilities to the SDV. In doing so, we faced two key challenges: Defining the metrics, and creating a useful process<strong>.</strong></p><p><strong>Metrics</strong></p><p>No single metric perfectly captures the different dimensions of synthetic data users may want to evaluate. Some want to preserve a high degree of mathematical likeness, others want to emphasize a particular column for machine learning predictions, and still others are more focused on threat models that can compromise privacy. </p><p>To address this, we created a separate library, <a href=\"https://github.com/sdv-dev/SDMetrics\">SDMetrics</a>, to define evaluation metrics. The library now includes a suite of metrics that cover differentiation of synthetic and real data, statistical likeness, and privacy.</p><p><strong>Application</strong></p><p>Rather than apply metrics on an ad-hoc basis, some SDV power users were creating mini-workflows to rapidly test out different models, datasets and evaluation criteria in succession. Inspired by their innovation, we created <a href=\"https://github.com/sdv-dev/SDGym\">SDGym</a>, a system that allows users to input models, datasets and success metrics to build a comprehensive evaluation framework.</p><h3 id=\"the-sdv-software-today\">The SDV Software Today</h3><p>The SDV software is continuously evolving based on community feedback. In this article, we discussed improvements to the workflow surrounding synthetic data generation, including data transformations, sampling methods and evaluation tools. Earlier, in <a href=\"https://sdv.dev/blog/community-feedback-models\">Part 1</a> of this series, we discussed the core synthetic data models themselves. In future blog articles, we plan to dig deeper into each of these areas, and to uncover new ones with you.</p><p>Like the SDV, this blog is a collaborative effort. Use our <a href=\"https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw\">Slack</a> to let us know which topics you'd like to hear more about. And as always, use <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a> to file technical issues with the system. Working together, we can make SDV the most trusted, transparent and comprehensive platform for synthetic data generation!</p><p><em>For other inquiries, please contact <a href=\"mailto: info@sdv.dev\">info@sdv.dev</a>.</em><br></p>","url":"https://sdv.ghost.io/community-feedback-workflow/","canonical_url":"https://sdv.dev/blog/community-feedback-workflow","uuid":"b55a798b-c1d5-4851-995d-d4b5931184b8","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"609c384488b3f9003e080016","reading_time":5}},"pageContext":{"slug":"community-feedback-workflow"}},"staticQueryHashes":["2061773391","2358152166","2362887240","2439066133","2561578252","2657115718","2731221146","2839364760","4145280475"]}