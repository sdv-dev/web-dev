{"componentChunkName":"component---src-templates-author-js","path":"/authors/neha/","result":{"data":{"ghostAuthor":{"slug":"neha","name":"Neha Patki","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","cover_image":null,"profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","location":"Boston, MA","website":"https://www.linkedin.com/in/nehapatki/","twitter":"@n4atki","facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__61e841116361ff003b9ca712","title":"Building the Unique Combinations Constraint in the SDV","slug":"building-unique-combinations","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2022/01/Banner-UC.png","excerpt":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","custom_excerpt":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","visibility":"public","created_at_pretty":"19 January, 2022","published_at_pretty":"25 January, 2022","updated_at_pretty":"26 January, 2022","created_at":"2022-01-19T11:49:21.000-05:00","published_at":"2022-01-25T13:25:20.000-05:00","updated_at":"2022-01-26T17:55:37.000-05:00","meta_title":"Building Unique Combinations","meta_description":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Sometimes, you want to limit the amount of permutations in your synthetic data. Explore the strategies we used for enforcing this kind of logic.","twitter_image":null,"twitter_title":"Building Unique Combinations","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Engineering","slug":"engineering","description":"The SDV engineering team is serving a global, open source user base. In our engineering blog, we highlight engineering challenges and design decisions we've made in support of our community.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Engineering","slug":"engineering","description":"The SDV engineering team is serving a global, open source user base. In our engineering blog, we highlight engineering challenges and design decisions we've made in support of our community.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By default, a machine learning model (ML) may not always learn the deterministic\nrules in your dataset. We've previously explored how the SDV allows user to \ninput their logic [https://sdv.dev/blog/eng-sdv-constraints/] using constraints.\nWith constraints, an SDV model produces logically correct data 100% of the time.\n\nWhile an end user might expect the constraint to \"just work,\" engineering this\nfunctionality requires some creative techniques. In this article, we'll describe\nthe techniques we used to build the UniqueCombinations constraint. You can also\nfollow along in our notebook\n[https://colab.research.google.com/drive/1bY8y6m7-CjTxWDepw32-ZT3Ubb9RGK5F?usp=sharing]\n.\n\n!pip install sdv==0.13.1\n\nimport numpy as np\nimport warnings\n\nwarnings.filterwarnings('ignore')\n\nWhat is a Unique Combinations Constraint?\nUsers frequently encounter logical constraints on the permutations -- mixing &\nmatching -- that are allowed in synthetic data.\n\nTo illustrate this, let's use the world_v1 dataset from the SDV tabular dataset\ndemos. This simple dataset describes the population of different cities around\nthe world.\n\nfrom sdv.demo import load_tabular_demo\n\ndata = load_tabular_demo('world_v1')\ndata = data.drop(['add_numerical'], axis=1) # not needed for this demo\ndata.head()\n\nRelationship between Name, CountryCode and District\n\nLooking at the data, we can observe that there is a special relationship between\nthe Name of the city, its CountryCode and its geographical District: When\ngenerating synthetic data, the model should not blindly mix-and-match these\nvalues. Instead, it should reference the real data to verify whether the\ncombination is valid. This is called a UniqueCombinations constraint.\n\nFor example, take a particular city, like Cambridge, which appears 3 times in\nour dataset.\n\ndata[data.Name == 'Cambridge']\n\nThe constraint states that Cambridge should only ever appear with GBR (England), \nCAN (Ontario) or USA (Massachusetts). It is invalid if it appears in any other\nregion -- for eg. Cambridge, France.\n\nHow does the SDV handle a Unique Combination out-of-the-box?\n\nLet's try running the sdv as-is on the dataset to see what happens. We'll use\nthe GaussianCopula model on our dataset.\n\nfrom sdv.tabular import GaussianCopula\n\nnp.random.seed(0)\n\nmodel = GaussianCopula(\n  categorical_transformer='label_encoding' # optimize speed\n) \nmodel.fit(data)\n\nNow, let's generate some rows to inspect the synthetic data.\n\nnp.random.seed(12)\nmodel.sample(5)\n\nAlthough the sdv is generating known city names, countries and districts, their\ncombinations don't make sense. We can also go back to our original example and\ngenerate only some rows for Cambridge.\n\nnp.random.seed(10)\n\nconditions = {'Name': 'Cambridge'}\nmodel.sample(5, conditions=conditions)\n\nThe result is a variety of Cambridges that aren't necessarily in USA, GBR, or\nCAN. These aren't valid cities!\n\nWhat's going on? The SDV models include probabilities that some unseen\ncombinations are possible. This is by design: Synthesizing new combinations --\nthat don't blatantly match the original data -- helps with privacy.\n\nHowever in this particular case, we aren't worried about the privacy of a city\nbelonging to a country or district. We actually do want the data to match. This\nis why we need to build a constraint.\n\nFixing the data using rejecting sampling\nIn our previous article [https://sdv.dev/blog/eng-sdv-constraints/], we\ndescribed a solution called reject_sampling that works on any type of constraint\nand is very easy to build: We simply create the synthetic data as usual and then\nthrow out (reject) any data that doesn't match.\n\nIn theory, this can solve our UniqueCombinations constraint. In practice, this\nstrategy is only efficient if the model can easily generate acceptable data.\nLet's calculate the chances of getting an acceptable combination (Name, \nCountryCode, District) from the model.\n\nnp.random.seed(0)\n\n# Sample data from the model\n# The sample may include combinations that aren't valid\nn = 100000\nnew_data = model.sample(n)\n\n# Calculate how many rows are valid\ncombo = ['Name', 'CountryCode', 'District']\nmerged = new_data.merge(data, left_on=combo, right_on=combo, how='left')\npassed = merged[merged['ID_y'].notna()].shape[0]\n\n# Print out our results\nprint(\"Valid rows: \", (passed/n)*100, \"%\")\nprint(\"Rejected rows: \", (1 - passed/n)*100, \"%\")\n\nValid rows:  0.038 %\nRejected rows:  99.96199999999999 %\n\nWith such a low probability of passing the constraint, this strategy can become\nintractable.\n\nFixing the data using transformations\nA more efficient strategy is for the ML model to learn the constraint directly,\nso it always produces acceptable data. We can do this by transforming the data\nin a clever way, forcing the model to learn the logic.\n\nOur previous article [https://sdv.dev/blog/eng-sdv-constraints/] described how\nto do this for a different constraint. Unfortunately, the exact same\ntransformation won't work to solve our current UniqueCombinations constraint. \nThe transform strategy requires a different, creative solution for each\nconstraint. So we have to start from scratch.\n\nCan you think of any other ways to enforce UniqueCombinations?\n\nA solution: Concatenating the data\n\nOne solution is to concatenate the data. That is, rather than treating the city \nName, CountryCode and District as separate items, we treat them as a single\nvalue. This will force the model to learn them as 1 single concept rather than\nas multiple columns that can be recombined.\n\nLet's see this in action.\n\n# create transformed data that concatenates the columns\ndata_transform = data.copy()\n\n# Concatenate the data using a separator\ndata_transform['concatenated'] = data_transform['Name'] + '#' + data_transform['CountryCode'] + '#' + data_transform['District']\n\n# We can drop the individual columns\ndata_transform.drop(labels=['Name', 'CountryCode', 'District'],\n                    axis=1, inplace=True)\n\ndata_transform.head()\n\nNow, we can train the model using the transformed (concatenated) data instead.\n\nnp.random.seed(35)\n\n# create a new model that will learn from the transformed data\nmodel_transform = GaussianCopula(categorical_transformer='label_encoding')\nmodel_transform.fit(data_transform)\n\n# this will produce transformed data\noutput = model_transform.sample()\noutput.head(5)\n\nTo get back realistic-looking data, we can convert the concatenated column back\ninto Name, City and District.\n\nimport pandas as pd\n\n# Split the conatenated column by the separator and save the reuslts\nnames = []\ncountrycodes = []\ndistricts = []\n\nfor x in output['concatenated']:\n  try:\n    name, countrycode, district = x.split('#')\n  except:\n    name, countrycode, district = [np.nan]*3\n  names.append(name)\n  countrycodes.append(countrycode)\n  districts.append(district)\n\n# Add the individual columns back in\noutput['Name'] = pd.Series(names)\noutput['CountryCode'] = pd.Series(countrycodes)\noutput['District'] = pd.Series(districts)\n\n# Drop the concatenated column\noutput.drop(labels=['concatenated'], axis=1, inplace=True)\n\nAs a result, the output now looks like our original data.\n\noutput.head()\n\nMost importantly, the Name, CountryCode and District columns now make sense!\n\nCaveats of transforming the data\n\nThe transform strategy is an efficient and elegant approach to modeling. But\nthere is a downside: The transform strategy might lose some mathematical\nproperties.\n\nTo see why, consider the model's perspective:\n\n * Cambridge#GBR#England is completely different from\n * Cambridge#USA#Massachusetts is completely different from\n * Boston#USA#Massachusetts\n\nThe problem is that two of these actually have something in common -- they are\nlocated in Massachusetts, USA. So the model will not be able to learn anything\nspecial about Massachusetts or USA as a whole.\n\nAs an example, let's see how well the model was able to learn populations of\nUS-based cities.\n\nimport matplotlib.pyplot as plt\n\n# Populations of real US cities\nreal_usa = data.loc[data['CountryCode'] == 'USA', 'Population']\n\n# Populations of synthetic US cities\nsynth_usa = output.loc[output['CountryCode'] == 'USA', 'Population']\n\n# Plot the distributions\nplt.ylabel('US City Data')\nplt.xlabel('Population')\n_ = plt.boxplot([real_usa, synth_usa],\n                showfliers=False,\n                labels=['Real', 'Synthetic'],\n                vert=False\n)\nplt.show()\n\nThe real data shows less variation in city population than the synthetic data.\nThe differences make sense because our model wasn't able to learn about the USA\nas one complete concept.\n\nCan we fix this? It's challenging to fix this issue without degrading the\nmathematical correlations in some other way. If you have any ideas, we welcome\nyou to join our discussion [https://github.com/sdv-dev/SDV/issues/414]!\n\nInputting a UniqueCombination into the SDV\nWe built the constraint -- both the reject_sampling and transform approaches --\ndirectly into the SDV library. If you have sdv installed, this is ready to use.\nImport the UniqueCombinations class from the constraints module.\n\nfrom sdv.constraints import UniqueCombinations\n\n# Create a Unique Combinations constraint\nunique_city_country_district = UniqueCombinations(\n  columns=['Name', 'CountryCode', 'District'],\n  handling_strategy='transform' # you can change this 'reject_sampling' too\n)\n\n# Create a new model using the constraint\nupdated_model = GaussianCopula(\n  constraints=[unique_city_country_district],\n  categorical_transformer='label_encoding'\n)\n\nNow, you can train the model on your data and sample synthetic data.\n\nnp.random.seed(35)\n\nupdated_model.fit(data)\nupdated_model.sample(5)\n\nAll of the synthetic data is guaranteed to follow the UniqueCombinations \nconstraint.\n\nTakeaways\n 1. We can identify a UniqueCombinations requirement by asking: Should it be\n    possible to further mix-and-match the data?\n 2. We can enforce any logical constraint by using reject sampling, which throws\n    out any invalid data. This is not efficient for UniqueCombinations.\n 3. An alternative approach is to transform the data, forcing the ML model to\n    learn the constraint. For UniqueCombinations we transformed the data by\n    concatenating it.\n 4. The logic for UniqueCombinations is already built into the SDV's constraints \n    module, and is ready to use.\n\nFurther reading:\n\n * Engineering Constraints Blog Article\n   [https://sdv.dev/blog/eng-sdv-constraints/]\n * Handling Constraints User Guide\n   [https://sdv.dev/SDV/user_guides/single_table/constraints.html]\n * Tabular Constraints API\n   [https://sdv.dev/SDV/api_reference/constraints/tabular.html]","html":"<p>By default, a machine learning model (ML) may not always learn the deterministic rules in your dataset. We've previously explored how the SDV allows user to <a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">input their logic</a> using constraints. With constraints, an SDV model produces logically correct data 100% of the time.</p><p>While an end user might expect the constraint to \"just work,\" engineering this functionality requires some creative techniques. In this article, we'll describe the techniques we used to build the <code>UniqueCombinations</code> constraint. You can also follow along in our <a href=\"https://colab.research.google.com/drive/1bY8y6m7-CjTxWDepw32-ZT3Ubb9RGK5F?usp=sharing\">notebook</a>.</p><pre><code>!pip install sdv==0.13.1</code></pre><pre><code class=\"language-python\">import numpy as np\nimport warnings\n\nwarnings.filterwarnings('ignore')</code></pre><h3 id=\"what-is-a-unique-combinations-constraint\">What is a Unique Combinations Constraint?</h3><p>Users frequently encounter logical constraints on the permutations -- mixing &amp; matching -- that are allowed in synthetic data.</p><p>To illustrate this, let's use the <code>world_v1</code> dataset from the SDV tabular dataset demos. This simple dataset describes the population of different cities around the world.</p><pre><code class=\"language-python\">from sdv.demo import load_tabular_demo\n\ndata = load_tabular_demo('world_v1')\ndata = data.drop(['add_numerical'], axis=1) # not needed for this demo\ndata.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1014\" height=\"362\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.51.49-AM.png 1014w\" sizes=\"(min-width: 720px) 720px\"></figure><p><strong>Relationship between <code>Name</code>, <code>CountryCode</code> and <code>District</code></strong></p><p>Looking at the data, we can observe that there is a special relationship between the <code>Name</code> of the city, its <code>CountryCode</code> and its geographical <code>District</code>: When generating synthetic data, the model should not blindly mix-and-match these values. Instead, it should <strong>reference the real data to verify whether the combination is valid.</strong> This is called a <code>UniqueCombinations</code> constraint.</p><p>For example, take a particular city, like <code>Cambridge</code>, which appears 3 times in our dataset.</p><pre><code class=\"language-python\">data[data.Name == 'Cambridge']</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1020\" height=\"248\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.53.07-AM.png 1020w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The constraint states that <code>Cambridge</code> should only ever appear with <code>GBR (England)</code>, <code>CAN (Ontario)</code> or <code>USA (Massachusetts)</code>. It is invalid if it appears in any other region -- for eg. Cambridge, France.</p><p><strong>How does the SDV handle a Unique Combination out-of-the-box?</strong></p><p>Let's try running the <code>sdv</code> as-is on the dataset to see what happens. We'll use the <code>GaussianCopula</code> model on our dataset.</p><pre><code class=\"language-python\">from sdv.tabular import GaussianCopula\n\nnp.random.seed(0)\n\nmodel = GaussianCopula(\n  categorical_transformer='label_encoding' # optimize speed\n) \nmodel.fit(data)</code></pre><p>Now, let's generate some rows to inspect the synthetic data.</p><pre><code class=\"language-python\">np.random.seed(12)\nmodel.sample(5)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.54.31-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"940\" height=\"360\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.54.31-AM.png 600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.54.31-AM.png 940w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Although the <code>sdv</code> is generating known city names, countries and districts, their combinations don't make sense. We can also go back to our original example and generate only some rows for <code>Cambridge</code>.</p><pre><code class=\"language-python\">np.random.seed(10)\n\nconditions = {'Name': 'Cambridge'}\nmodel.sample(5, conditions=conditions)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1022\" height=\"364\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.55.06-AM.png 1022w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The result is a variety of Cambridges that aren't necessarily in USA, GBR, or CAN. These aren't valid cities!</p><p><strong>What's going on?</strong> The SDV models include probabilities that some unseen combinations are possible. This is by design: Synthesizing new combinations -- that don't blatantly match the original data -- helps with privacy.</p><p>However in this particular case, we aren't worried about the privacy of a city belonging to a country or district. We actually <em>do</em> want the data to match. This is why we need to build a constraint.</p><h3 id=\"fixing-the-data-using-rejecting-sampling\">Fixing the data using rejecting sampling</h3><p>In our <a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">previous article</a>, we described a solution called <code>reject_sampling</code> that works on any type of constraint and is very easy to build: We simply create the synthetic data as usual and then throw out (reject) any data that doesn't match.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-02.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"883\" height=\"316\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/UniqueCombinations-02.png 600w, https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-02.png 883w\" sizes=\"(min-width: 720px) 720px\"></figure><p>In theory, this can solve our <code>UniqueCombinations</code> constraint. In practice, this strategy is only efficient if the model can easily generate acceptable data. Let's calculate the chances of getting an acceptable combination (<code>Name</code>, <code>CountryCode</code>, <code>District</code>) from the model.</p><pre><code class=\"language-python\">np.random.seed(0)\n\n# Sample data from the model\n# The sample may include combinations that aren't valid\nn = 100000\nnew_data = model.sample(n)\n\n# Calculate how many rows are valid\ncombo = ['Name', 'CountryCode', 'District']\nmerged = new_data.merge(data, left_on=combo, right_on=combo, how='left')\npassed = merged[merged['ID_y'].notna()].shape[0]\n\n# Print out our results\nprint(\"Valid rows: \", (passed/n)*100, \"%\")\nprint(\"Rejected rows: \", (1 - passed/n)*100, \"%\")</code></pre><pre><code>Valid rows:  0.038 %\nRejected rows:  99.96199999999999 %</code></pre><p>With such a low probability of passing the constraint, this strategy can become intractable.</p><h3 id=\"fixing-the-data-using-transformations\">Fixing the data using transformations</h3><p>A more efficient strategy is for the ML model to learn the constraint directly, so it always produces acceptable data. We can do this by transforming the data in a clever way, forcing the model to learn the logic.</p><p>Our <a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">previous article</a> described how to do this for a different constraint. Unfortunately, the exact same transformation won't work to solve our current <code>UniqueCombinations</code> constraint. <strong>The transform strategy requires a different, creative solution for each constraint.</strong> So we have to start from scratch.</p><p>Can you think of any other ways to enforce <code>UniqueCombinations</code>?</p><p><strong>A solution: Concatenating the data</strong></p><p>One solution is to concatenate the data. That is, rather than treating the city <code>Name</code>, <code>CountryCode</code> and <code>District</code> as separate items, we treat them as a single value. This will force the model to learn them as 1 single concept rather than as multiple columns that can be recombined.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-01.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1524\" height=\"1200\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/UniqueCombinations-01.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/UniqueCombinations-01.png 1000w, https://sdv.ghost.io/content/images/2022/01/UniqueCombinations-01.png 1524w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Let's see this in action.</p><pre><code class=\"language-python\"># create transformed data that concatenates the columns\ndata_transform = data.copy()\n\n# Concatenate the data using a separator\ndata_transform['concatenated'] = data_transform['Name'] + '#' + data_transform['CountryCode'] + '#' + data_transform['District']\n\n# We can drop the individual columns\ndata_transform.drop(labels=['Name', 'CountryCode', 'District'],\n                    axis=1, inplace=True)\n\ndata_transform.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.21-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"828\" height=\"368\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.58.21-AM.png 600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.21-AM.png 828w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Now, we can train the model using the transformed (concatenated) data instead.</p><pre><code class=\"language-python\">np.random.seed(35)\n\n# create a new model that will learn from the transformed data\nmodel_transform = GaussianCopula(categorical_transformer='label_encoding')\nmodel_transform.fit(data_transform)\n\n# this will produce transformed data\noutput = model_transform.sample()\noutput.head(5)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.53-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"882\" height=\"368\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.58.53-AM.png 600w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.58.53-AM.png 882w\" sizes=\"(min-width: 720px) 720px\"></figure><p>To get back realistic-looking data, we can convert the concatenated column back into <code>Name</code>, <code>City</code> and <code>District</code>.</p><pre><code class=\"language-python\">import pandas as pd\n\n# Split the conatenated column by the separator and save the reuslts\nnames = []\ncountrycodes = []\ndistricts = []\n\nfor x in output['concatenated']:\n  try:\n    name, countrycode, district = x.split('#')\n  except:\n    name, countrycode, district = [np.nan]*3\n  names.append(name)\n  countrycodes.append(countrycode)\n  districts.append(district)\n\n# Add the individual columns back in\noutput['Name'] = pd.Series(names)\noutput['CountryCode'] = pd.Series(countrycodes)\noutput['District'] = pd.Series(districts)\n\n# Drop the concatenated column\noutput.drop(labels=['concatenated'], axis=1, inplace=True)</code></pre><p>As a result, the output now looks like our original data.</p><pre><code class=\"language-python\">output.head()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1020\" height=\"368\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-11.59.41-AM.png 1020w\" sizes=\"(min-width: 720px) 720px\"></figure><p>Most importantly, the <code>Name</code>, <code>CountryCode</code> and <code>District</code> columns now make sense!</p><p><strong>Caveats of transforming the data</strong></p><p>The transform strategy is an efficient and elegant approach to modeling. But there is a downside: <strong>The transform strategy might lose some mathematical properties.</strong></p><p>To see why, consider the model's perspective:</p><ul><li><code>Cambridge#GBR#England</code> is completely different from</li><li><code>Cambridge#USA#Massachusetts</code> is completely different from</li><li><code>Boston#USA#Massachusetts</code></li></ul><p>The problem is that two of these actually have something in common -- they are located in <code>Massachusetts, USA</code>. So the model will not be able to learn anything special about <code>Massachusetts</code> or <code>USA</code> as a whole.</p><p>As an example, let's see how well the model was able to learn populations of US-based cities.</p><pre><code class=\"language-python\">import matplotlib.pyplot as plt\n\n# Populations of real US cities\nreal_usa = data.loc[data['CountryCode'] == 'USA', 'Population']\n\n# Populations of synthetic US cities\nsynth_usa = output.loc[output['CountryCode'] == 'USA', 'Population']\n\n# Plot the distributions\nplt.ylabel('US City Data')\nplt.xlabel('Population')\n_ = plt.boxplot([real_usa, synth_usa],\n                showfliers=False,\n                labels=['Real', 'Synthetic'],\n                vert=False\n)\nplt.show()</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1022\" height=\"500\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.00.53-PM.png 1022w\" sizes=\"(min-width: 720px) 720px\"></figure><p>The real data shows less variation in city population than the synthetic data. The differences make sense because our model wasn't able to learn about the USA as one complete concept.</p><p><strong>Can we fix this?</strong> It's challenging to fix this issue without degrading the mathematical correlations in some other way. If you have any ideas, we welcome you to <a href=\"https://github.com/sdv-dev/SDV/issues/414\" rel=\"nofollow\">join our discussion</a>!</p><h3 id=\"inputting-a-uniquecombination-into-the-sdv\">Inputting a UniqueCombination into the SDV</h3><p>We built the constraint -- both the <code>reject_sampling</code> and <code>transform</code> approaches -- directly into the SDV library. If you have <code>sdv</code> installed, this is ready to use. Import the <code>UniqueCombinations</code> class from the <code>constraints</code> module.</p><pre><code class=\"language-python\">from sdv.constraints import UniqueCombinations\n\n# Create a Unique Combinations constraint\nunique_city_country_district = UniqueCombinations(\n  columns=['Name', 'CountryCode', 'District'],\n  handling_strategy='transform' # you can change this 'reject_sampling' too\n)\n\n# Create a new model using the constraint\nupdated_model = GaussianCopula(\n  constraints=[unique_city_country_district],\n  categorical_transformer='label_encoding'\n)</code></pre><p>Now, you can train the model on your data and sample synthetic data.</p><pre><code class=\"language-python\">np.random.seed(35)\n\nupdated_model.fit(data)\nupdated_model.sample(5)</code></pre><figure class=\"kg-card kg-image-card\"><img src=\"https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png\" class=\"kg-image\" alt loading=\"lazy\" width=\"1146\" height=\"382\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png 600w, https://sdv.ghost.io/content/images/size/w1000/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png 1000w, https://sdv.ghost.io/content/images/2022/01/Screen-Shot-2022-01-19-at-12.02.30-PM.png 1146w\" sizes=\"(min-width: 720px) 720px\"></figure><p>All of the synthetic data is guaranteed to follow the <code>UniqueCombinations</code> constraint.</p><h3 id=\"takeaways\">Takeaways</h3><ol><li>We can identify a <code>UniqueCombinations</code> requirement by asking: Should it be possible to further mix-and-match the data?</li><li>We can enforce any logical constraint by using reject sampling, which throws out any invalid data. This is not efficient for <code>UniqueCombinations</code>.</li><li>An alternative approach is to transform the data, forcing the ML model to learn the constraint. For <code>UniqueCombinations</code> we transformed the data by concatenating it.</li><li>The logic for <code>UniqueCombinations</code> is already built into the SDV's <code>constraints</code> module, and is ready to use.</li></ol><p>Further reading:</p><ul><li><a href=\"https://sdv.dev/blog/eng-sdv-constraints/\" rel=\"nofollow\">Engineering Constraints Blog Article</a></li><li><a href=\"https://sdv.dev/SDV/user_guides/single_table/constraints.html\" rel=\"nofollow\">Handling Constraints User Guide</a></li><li><a href=\"https://sdv.dev/SDV/api_reference/constraints/tabular.html\" rel=\"nofollow\">Tabular Constraints API</a></li></ul>","url":"https://sdv.ghost.io/building-unique-combinations/","canonical_url":null,"uuid":"01fb2714-6b15-4055-8a77-e7fde4a0f944","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61e841116361ff003b9ca712","reading_time":7}},{"node":{"id":"Ghost__Post__61a68d091b683e0048b2a2f3","title":"User input to enhance synthetic data generation","slug":"user-input-synthetic-data","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2021/11/Banner.png","excerpt":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","custom_excerpt":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","visibility":"public","created_at_pretty":"30 November, 2021","published_at_pretty":"01 December, 2021","updated_at_pretty":"02 December, 2021","created_at":"2021-11-30T15:43:53.000-05:00","published_at":"2021-12-01T11:06:49.000-05:00","updated_at":"2021-12-02T18:23:08.000-05:00","meta_title":"User input to enhance synthetic data generation","meta_description":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"ML models learn some rules out of the box, while other logic requires more work. Which is which? Read more to find out.","twitter_image":"https://sdv.ghost.io/content/images/2021/11/Banner-1.png","twitter_title":"User input to enhance synthetic data generation","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"In our previous article [https://sdv.dev/blog/fake-to-synthetic-ml], we explored\nhow machine learning (ML) plays a key role in synthetic data creation. One of\nthe biggest strengths of ML is automatic rule detection (also known in ML terms\nas correlations): The algorithms are designed to learn patterns in the data,\neven without additional user input. The result is synthetic data that resembles\nthe original, right down to its mathematical properties!\n\nHowever, in some cases, applying an ML model right out of the box may not\nimmediately achieve the desired result. In this article, we'll explore the\nstrengths of ML models and go through those areas where user input may be\nrequired.\n\nStrengths of ML Models\nThe goal of any ML-based synthetic data generation software is to learn from and\nemulate the input data. To illustrate this, let's pretend you work in the car\ninsurance business, and you're in possession of a real dataset related to\ndrivers and their insurance:\n\nAn example dataset, including license and collision coverage information\nassociated with different drivers.An ML-based system, such as the Synthetic Data Vault\n[https://sdv.dev/blog/intro-to-sdv/] (SDV), will learn patterns from the real\ndata and use it to create new synthetic data. Recall some of the important\npatterns that ML algorithms detect:\n\n * Shapes. The general shape of the data. For example, in the dataset above, 50%\n   of drivers have Collision Coverage and the Annual Premium is uniformly\n   scattered between $3,000 and $9,000.\n * Correlations. The trends within the data. For example, having Collision\n   Coverage -- especially Standard coverage -- means a higher Annual Premium.\n\nThese shapes and correlations will be present in the synthetic data that is\noutputted by the ML model, as shown below.\n\nAn example of a synthetic dataset created by an ML-based algorithm. The\nalgorithm will learn patterns from the real data and emulate them.Perhaps the single biggest strength of an ML algorithm is its ability to learn\nrules by looking for general patterns in the data, using probability and\nstatistics.\n\nWhat ML models do not learn out of the box\nLet's take a closer look at the synthetic car insurance data. You might notice\nthat two of the rows in the synthetic data don't make complete sense. Below,\nwe've highlighted the errors.\n\nThe synthetic car insurance data, with errors highlighted.Do you see what has\ngone wrong? In the first row, the license expired 3 years earlier than it was\nissued. In the last row, a driver without Collision Coverage has a Collision\nPolicy Type. Additionally, the same Customer ID has been repeated in Row 3 and\nRow 4.\n\nThere are three rules that the ML algorithm did not follow:\n\n 1. License Expiration > License Issue Year\n 2. If Has Collision Coverage = NO, then Collision Policy Type must be empty\n 3. All Customer IDs must be unique\n\nWhy does the ML model easily pick up on some rules and not others? To answer\nthis question, we can look closely at the rules themselves. All of the rules\nthat the ML model successfully learned -- including the distribution shapes and\nthe correlations -- were based on general trends. These probabilistic rules \napply to a majority of the relationships within the dataset, but not all of\nthem. Although they have to make sense in aggregate, a few rows may be\nexceptions.\n\nBy contrast, the rules that the ML model failed to learn were stricter. These \ndeterministic rules describe intrinsic laws of nature, time or logic. Each and\nevery row must adhere to them, and they won't change regardless of  how much (or\nhow little) data has been given to the ML model.\n\nTo continue with the driving theme: A probabilistic rule is like a yield sign,\nsignaling a general recommendation that works out differently for each\nindividual situation -- some cars may need to stop, while others just slow down.\nMeanwhile, a deterministic rule is like a stop sign, demanding that every single\ncar must come to a full stop.\n\nA probabilistic rule applies to a majority of rows, but leaves room for\nexceptions. Meanwhile, a deterministic rule applies to every single row.By\ndefault, our ML model assumed that all rules were probabilistic. When this\nhappens, synthetic data still generally follows the desired properties -- for\nexample, License Expiration > License Issue Year -- for most of the rows, but\nnot for every row.\n\nImproving the ML Models using constraints\nJust because the ML model didn't automatically follow a deterministic rule\ndoesn't mean that it can't. It's possible to improve the model so that it\nunderstands this type of rule. As a user working with the SDV, you can input\ndeterministic rules into your model using constraints.\n\nAn ML model built using constraints will accommodate both probabilistic and\ndeterministic rules.\n\nDo you need SDV constraints?\n\nDeterministic rules are often easy to spot in your dataset: They are the rules\nthat every single row must follow in order to be valid, regardless of how much\ndata there is overall.  But even if you identify the right constraints, there\nare some cases where you might not actually want to supply them to the SDV.\n\nBecause the SDV learns probabilistic rules, most of the synthesized data is\ngenerally valid. Having a few errors sprinkled in might actually be beneficial\nif you want your synthetic data to cover some edge cases. For example, if you're\nusing the synthetic data to test insurance claim software, leaving in some weird\ndata points might help you ensure that the software can handle unexpected cases\n-- like the License Expiration accidentally being set too early.\n\nThe figure below shows a few questions you can ask to determine whether adding a\nconstraint is the right approach.\n\nShould you input a rule using constraints? First, determine whether the rule is\ndeterministic, and then take your use case into account.The SDV Constraints\noffering\n\nIf you decide that adding deterministic rules is important for generating your\nsynthetic data, the SDV has many different constraints to choose from! The table\nbelow describes the constraints you would need in order to define the\ndeterministic rules that would best mold your Car Insurance dataset.\n\nThe GreaterThan, ColumnFormula and Unique constraints -- all available in the\nSDV -- set the deterministic rules that ensure your synthetic Car Insurance Data\nis useful and makes sense.The SDV offers many more possible constraints,\nincluding:\n\n * UniqueCombinations\n * Positive and Negative\n * Rounding\n * Between\n * OneHotEncoding\n\nYou can add multiple constraints to the same dataset in order to accommodate all\nthe deterministic rules you need. For more details, read the Constraints User\nGuide [https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html].\n\nTakeaways\nIn this article, we learned that:\n\n * Data is governed by rules. The SDV automatically learns probabilistic rules,\n   which describe overall trends or patterns in the data.\n * However, sometimes the data has deterministic rules, which are always\n   inherent no matter how much or how little data there is. ML-based systems,\n   including the SDV, may not enforce deterministic rules out of the box.\n * Users can input deterministic rules to the SDV using constraints. To figure\n   out whether you should input a constraint, ask yourself whether there are any\n   rules that the data must always follow. There are many constraints to choose\n   from.\n\nIn future articles, we'll dive deeper into this topic. We'll explore the\ntechnical details behind constraints, and how exactly the SDV's ML models are\nable to learn deterministic rules.","html":"<p>In our <a href=\"https://sdv.dev/blog/fake-to-synthetic-ml\">previous article</a>, we explored how machine learning (ML) plays a key role in synthetic data creation. One of the biggest strengths of ML is <em>automatic rule detection</em> (also known in ML terms as <em>correlations</em>): The algorithms are designed to learn patterns in the data, even without additional user input. The result is synthetic data that resembles the original, right down to its mathematical properties!</p><p>However, in some cases, applying an ML model right out of the box may not immediately achieve the desired result. In this article, we'll explore the strengths of ML models and go through those areas where user input may be required.</p><h3 id=\"strengths-of-ml-models\">Strengths of ML Models</h3><p>The goal of any ML-based synthetic data generation software is to learn from and emulate the input data. To illustrate this, let's pretend you work in the car insurance business, and you're in possession of a real dataset related to drivers and their insurance:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-03.png\" class=\"kg-image\" alt=\"An example dataset, including license and collision coverage information associated with different drivers.\" loading=\"lazy\" width=\"1916\" height=\"835\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-03.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-03.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-03.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-03.png 1916w\" sizes=\"(min-width: 720px) 720px\"><figcaption>An example dataset, including license and collision coverage information associated with different drivers.</figcaption></figure><p>An ML-based system, such as the <a href=\"https://sdv.dev/blog/intro-to-sdv/\">Synthetic Data Vault</a> (SDV), will learn patterns from the real data and use it to create new synthetic data. Recall some of the important patterns that ML algorithms detect:</p><ul><li><strong><strong><strong>Shapes. </strong></strong></strong>The general shape of the data. For example, in the dataset above, 50% of drivers have Collision Coverage and the Annual Premium is uniformly scattered between $3,000 and $9,000.</li><li><strong><strong><strong>Correlations.</strong> </strong></strong>The trends within the data. For example, having Collision Coverage -- especially Standard coverage -- means a higher Annual Premium.</li></ul><p>These shapes and correlations will be present in the synthetic data that is outputted by the ML model, as shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-04.png\" class=\"kg-image\" alt=\"An example of a synthetic dataset created by an ML-based algorithm. The algorithm will learn patterns from the real data and emulate them.\" loading=\"lazy\" width=\"1875\" height=\"832\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-04.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-04.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-04.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-04.png 1875w\" sizes=\"(min-width: 720px) 720px\"><figcaption>An example of a synthetic dataset created by an ML-based algorithm. The algorithm will learn patterns from the real data and emulate them.</figcaption></figure><p>Perhaps <strong>the single biggest strength of an ML algorithm is its ability to learn rules by looking for general patterns in the data,</strong> using probability and statistics.</p><h3 id=\"what-ml-models-do-not-learn-out-of-the-box\">What ML models do not learn out of the box</h3><p>Let's take a closer look at the synthetic car insurance data. You might notice that two of the rows in the synthetic data don't make complete sense. Below, we've highlighted the errors.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-05.png\" class=\"kg-image\" alt=\"The synthetic car insurance data, with errors highlighted. \" loading=\"lazy\" width=\"1867\" height=\"831\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-05.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-05.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-05.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-05.png 1867w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The synthetic car insurance data, with errors highlighted.</figcaption></figure><p>Do you see what has gone wrong? In the first row, the license expired 3 years earlier than it was issued. In the last row, a driver without Collision Coverage has a Collision Policy Type. Additionally, the same Customer ID has been repeated in Row 3 and Row 4.</p><p>There are three rules that the ML algorithm did not follow:</p><ol><li>License Expiration &gt; License Issue Year</li><li>If Has Collision Coverage = NO, then Collision Policy Type must be empty</li><li>All Customer IDs must be unique</li></ol><p>Why does the ML model easily pick up on some rules and not others? To answer this question, we can look closely at the rules themselves. All of the rules that the ML model successfully learned -- including the distribution shapes and the correlations -- were based on general trends. These <strong>probabilistic rules</strong> apply to a majority of the relationships within the dataset, but not all of them. Although they have to make sense in aggregate, a few rows may be exceptions.</p><p>By contrast, the rules that the ML model failed to learn were stricter. These <strong>deterministic rules</strong> describe intrinsic laws of nature, time or logic. Each and every row must adhere to them, and they won't change regardless of  how much (or how little) data has been given to the ML model.</p><p>To continue with the driving theme: A probabilistic rule is like a yield sign, signaling a general recommendation that works out differently for each individual situation -- some cars may need to stop, while others just slow down. Meanwhile, a deterministic rule is like a stop sign, demanding that every single car must come to a full stop.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-06.png\" class=\"kg-image\" alt=\"A probabilistic rule applies to a majority of rows, but leaves room for exceptions. Meanwhile, a deterministic rule applies to every single row.\" loading=\"lazy\" width=\"1607\" height=\"662\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-06.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-06.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-06.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-06.png 1607w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A probabilistic rule applies to a majority of rows, but leaves room for exceptions. Meanwhile, a deterministic rule applies to every single row.</figcaption></figure><p><strong>By default, our ML model assumed that all rules were probabilistic.</strong> When this happens, synthetic data still generally follows the desired properties -- for example, License Expiration &gt; License Issue Year -- for <em>most</em> of the rows, but not for every row.</p><h3 id=\"improving-the-ml-models-using-constraints\">Improving the ML Models using constraints</h3><p>Just because the ML model didn't automatically follow a deterministic rule doesn't mean that it can't. It's possible to improve the model so that it understands this type of rule. As a user working with the SDV, you can input deterministic rules into your model using <strong>constraints</strong>.</p><p>An ML model built using constraints will accommodate both probabilistic and deterministic rules.</p><p><strong>Do you need SDV constraints?</strong></p><p>Deterministic rules are often easy to spot in your dataset: They are the rules that every single row must follow in order to be valid, regardless of how much data there is overall.  But even if you identify the right constraints, there are some cases where you might not actually want to supply them to the SDV.</p><p>Because the SDV learns probabilistic rules, most of the synthesized data is generally valid. Having a few errors sprinkled in might actually be beneficial if you want your synthetic data to cover some edge cases. For example, if you're using the synthetic data to test insurance claim software, leaving in some weird data points might help you ensure that the software can handle unexpected cases -- like the License Expiration accidentally being set too early.</p><p>The figure below shows a few questions you can ask to determine whether adding a constraint is the right approach.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/12/Figure-07.png\" class=\"kg-image\" alt=\"Should you input a rule using constraints? First, determine whether the rule is deterministic, and then take your use case into account.\" loading=\"lazy\" width=\"2000\" height=\"586\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/12/Figure-07.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/12/Figure-07.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/12/Figure-07.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/12/Figure-07.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Should you input a rule using constraints? First, determine whether the rule is deterministic, and then take your use case into account.</figcaption></figure><p><strong>The SDV Constraints offering</strong></p><p>If you decide that adding deterministic rules is important for generating your synthetic data, the SDV has many different constraints to choose from! The table below describes the constraints you would need in order to define the deterministic rules that would best mold your Car Insurance dataset.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Figure-08.png\" class=\"kg-image\" alt=\"The GreaterThan, ColumnFormula and Unique constraints -- all available in the SDV -- set the deterministic rules that ensure your synthetic  Car Insurance Data is useful and makes sense.\" loading=\"lazy\" width=\"2000\" height=\"578\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Figure-08.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Figure-08.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Figure-08.png 1600w, https://sdv.ghost.io/content/images/2021/11/Figure-08.png 2204w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The GreaterThan, ColumnFormula and Unique constraints -- all available in the SDV -- set the deterministic rules that ensure your synthetic Car Insurance Data is useful and makes sense.</figcaption></figure><p>The SDV offers many more possible constraints, including:</p><ul><li>UniqueCombinations</li><li>Positive and Negative</li><li>Rounding</li><li>Between</li><li>OneHotEncoding</li></ul><p>You can add multiple constraints to the same dataset in order to accommodate all the deterministic rules you need. For more details, read the <a href=\"https://sdv.dev/SDV/user_guides/single_table/handling_constraints.html\">Constraints User Guide</a>.</p><h3 id=\"takeaways\">Takeaways</h3><p>In this article, we learned that:</p><ul><li>Data is governed by rules. The SDV automatically learns probabilistic rules, which describe overall trends or patterns in the data.</li><li>However, sometimes the data has <strong>deterministic rules</strong>, which are always inherent no matter how much or how little data there is. ML-based systems, including the SDV, may not enforce deterministic rules out of the box.</li><li>Users can input deterministic rules to the SDV using <strong>constraints</strong>. To figure out whether you should input a constraint, ask yourself whether there are any rules that the data must always follow. There are many constraints to choose from.</li></ul><p>In future articles, we'll dive deeper into this topic. We'll explore the technical details behind constraints, and how exactly the SDV's ML models are able to learn deterministic rules.<br></p>","url":"https://sdv.ghost.io/user-input-synthetic-data/","canonical_url":null,"uuid":"e72409d4-6d39-46dc-a973-3e5f9f039dd7","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61a68d091b683e0048b2a2f3","reading_time":5}},{"node":{"id":"Ghost__Post__61927ca167598b003b3d944a","title":"From fake to synthetic data: Machine learning changes the game","slug":"fake-to-synthetic-ml","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2021/11/Article-13.png","excerpt":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","custom_excerpt":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","visibility":"public","created_at_pretty":"15 November, 2021","published_at_pretty":"16 November, 2021","updated_at_pretty":"17 November, 2021","created_at":"2021-11-15T10:28:33.000-05:00","published_at":"2021-11-16T11:33:56.000-05:00","updated_at":"2021-11-17T14:21:39.000-05:00","meta_title":"From fake to synthetic data: Machine learning changes the game","meta_description":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Creating fake data is an old concept -- but machine learning is a whole new ballgame. Learn about why ML is a key ingredient to synthetic data.","twitter_image":null,"twitter_title":"From fake to synthetic data: Machine learning changes the game","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Data is a great source of information. Real data — which is based on\nobservations of real-world phenomena like weather, movements on a factory floor\nor the activities of a user base — can help us notice trends, increase business\nefficiency and solve problems. \n\nBut data can be helpful even if it isn’t real. This data, sometimes called fake\nor test data, doesn’t come directly from real-world observations, but is instead\nartificially crafted by a human or machine. The latest and most complex\niteration of this data type — what we call synthetic data — builds on previous\nwork done in this space. \n\nIn this article, we'll go through the history of fake data. By the end, you'll\nbe able to answer the following questions:\n\n * What were the original motivations and tools for manually creating data?\n * What differentiates synthetic data from other types of fake data?\n * What role does machine learning play in generating synthetic data?\n\nThe Dawn of Fake Data: Test Data Management\nOne group of people has worked with fake data for a long time: software\nengineers. They need data in order to test the systems they build, and the real\nstuff isn't always usable (for example, due to privacy). \n\nLet's pretend it's the early 2000s, and you're an IT professional working at a\nbank. You're responsible for the software that updates account balances after\neach transaction. You'd like to test this software before putting it into\nproduction. What do you do?\n\nMost likely, you'll come up with a few test scenarios to ensure that your\nfunctionality — updating the balance — can properly handle a variety of inputs.\n\nThis table shows a few scenarios you may use to test your system. In these\nscenarios, you're testing how a monetary transfer of $20 changes the balance in\ndifferent accounts.Notice that in order to create these scenarios, you had to\ngenerate data: various starting balances ($500, $20, $10) as well as a transfer\namount ($20). This is an early version of using fake data in order to test your\nsoftware!\n\nUsing Tools for Manual Creation\n\nNow let's fast forward in time. Over the years, your software has gotten even\nmore complex, and you're constantly adding new functionalities. For example,\nmaybe you start allowing transfers with foreign currency. \n\nYou need to test these functionalities before you roll them out. To save time,\nyou might end up using -- or creating -- a tool that allows you to generate and\nmanage fake data for testing. \n\nThe simplest tool may be a basic permutation, as illustrated below.\n\nA simple manual test data generation tool that uses permutations. The resulting\nscenarios -- with different starting balances, transfer amounts and transfer\ncurrencies -- are outputted as a data table.A more sophisticated tool might\nallow you greater control over the rules the data must follow. It will also\nallow you to create more columns as your functionalities increase. For example,\nmaybe the bank now offers two different account types: Premium and Normal. \n\nNow you need a test data generation tool that can handle all of these variables\nand come out with something like this:\n\nA more sophisticated test data tool will allow you to specify rules manually. It\nwill follow them to generate test data.Many test data management tools use\nsophisticated logic to precisely create these data columns and their values. But\nthe rules they use are manually written, and rely on human intuition and domain\nknowledge. For example:\n\n * Account type = Premium 10% of the time and Normal 90% of the time\n * Starting balance is between $10,000 and $250,000 if Account type = Premium\n   or between -$1,000 and $10,000 if Account type = Normal\n * Transfer amount follows a bell curve with a mean of $7,500 and standard\n   deviation of $1,000\n * Etc.\n\nThere are downsides to this manual approach. It takes time and effort to come up\nwith these rules, to keep track of them, and to update them as your application\nchanges.\n\nAdding Machine Learning\nAdopting machine learning (ML) opens up entirely new avenues in data generation.\nIn the process, it gets rid of some of these downsides.\n\nAt a high level, ML-based software (such as the Synthetic Data Vault\n[https://sdv.dev/blog/intro-to-sdv/]) works in three steps:\n\n 1. The user inputs real data into the ML software\n 2. The ML software automatically learns patterns in the data\n 3. The software outputs data that contains those patterns\n\nLet's go back to our banking example to see how this works. It's now 2021 and\nyou're using the SDV [https://sdv.dev/] to generate your test data. You input\nall the transactions your bank has handled in the last week. \n\nAfter modeling, the SDV outputs entirely new data that looks and behaves like\nthe original. An illustration of this is shown below.\n\nWith ML tools (like the SDV), you input real data into the software. The\nsoftware then learns patterns from the data and outputs data that matches those\npatterns.Notice that the output data contains many of the same properties as the\noriginal. The model learned all of the following information:\n\n * Ranges & Categories. Transfers range from $5K to $10K. Bank accounts can be\n   either premium or normal. Etc.\n * Shapes. 10% of accounts are premium. Transfers follow a bell curve\n   distribution with a mean of $7,500 and a standard deviation of $1,000. Etc.\n * Correlations. Premium bank accounts tend to have higher balances ($10K to\n   $250K) than normal accounts (-$1K to $10K).\n\nIn other words: while the old test data management tools required you to\nmanually come up with rules, ML-based tools learn these rules automatically. \nMoreover, they can learn new information. For example, the ML picked upon a\ncouple of extra correlations:\n\n * Premium accounts are more likely to transfer foreign currency.\n * Normal accounts are more likely to be overdrawn (transfer more than their\n   current balance).\n\nUsing an ML-based data generation tool will help you ensure that your software\nis robust against these typical cases. And while manual data generation tools\ngenerate fake data, ML-based approaches generate what we call synthetic data.\n\nAsk whether you had to input any real data or rules. Based on this, you'll know\nwhether you are dealing with synthetic data or fake data.Benefits of Synthetic\nData\n\nThere are some clear advantages to using synthetic data over fake data,\nespecially in software testing. Below, we've detailed a few.\n\n * Saves time with automation. Because ML automatically learns patterns from the\n   real data, there is no need to spend a lot of time coming up with and\n   inputting rules. ML learns rules that you may even miss.\n * Is usable by non-experts. Realistic fake data can only be generated by domain\n   experts, who know the precise rules governing the dataset. However, anyone\n   can generate synthetic data. All they have to do is input the real data and\n   the ML software takes care of the rest!\n * Increases adaptability. Applications and data will inevitably change over\n   time. It's easy to update synthetic data as this happens, simply by\n   retraining the ML model with newer data.\n\nBenefits of synthetic data expand beyond software testing. The SDV Community is\nusing synthetic data for an ever-increasing variety of tasks, including machine\nlearning development, de-biasing datasets and scenario planning.\n\nKey Takeaways\nIn this article, we surveyed numerous ways of creating and using data  that is\nnot real. In particular, we learned that:\n\n * Creating fake data is not a novel concept. Older generations of tools will\n   output fake data when given an explicit list of rules. This is especially\n   useful for software testing.\n * Adding ML to this process is a newer evolution. Users input real data into\n   the ML model, and it's able to automatically infer the rules. Data generated\n   using ML-based systems is known as synthetic data.\n * Synthetic data's key advantages include its automation and adaptability. The\n   uses of synthetic data expand beyond software testing.\n\nIn future articles, we'll put ML models to the test! We'll uncover their\nstrengths and weaknesses, and guide you through getting the most from synthetic\ndata using the Synthetic Data Vault.","html":"<p>Data is a great source of information. Real data — which is based on observations of real-world phenomena like weather, movements on a factory floor or the activities of a user base — can help us notice trends, increase business efficiency and solve problems. </p><p>But data can be helpful even if it isn’t real. This data, sometimes called fake or test data, doesn’t come directly from real-world observations, but is instead artificially crafted by a human or machine. The latest and most complex iteration of this data type — what we call synthetic data — builds on previous work done in this space. </p><p>In this article, we'll go through the history of fake data. By the end, you'll be able to answer the following questions:</p><ul><li>What were the original motivations and tools for manually creating data?</li><li>What differentiates synthetic data from other types of fake data?</li><li>What role does machine learning play in generating synthetic data?</li></ul><h3 id=\"the-dawn-of-fake-data-test-data-management\">The Dawn of Fake Data: Test Data Management</h3><p>One group of people has worked with fake data for a long time: software engineers. They need data in order to test the systems they build, and the real stuff isn't always usable (for example, due to privacy). </p><p>Let's pretend it's the early 2000s, and you're an IT professional working at a bank. You're responsible for the software that updates account balances after each transaction. You'd like to test this software before putting it into production. What do you do?</p><p>Most likely, you'll come up with a few test scenarios to ensure that your functionality — updating the balance — can properly handle a variety of inputs.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-09--1-.png\" class=\"kg-image\" alt=\"This table shows a few scenarios you may use to test your system. In these scenarios, you're testing how a monetary transfer of $20 changes the balance in different accounts.\" loading=\"lazy\" width=\"2000\" height=\"541\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-09--1-.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-09--1-.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-09--1-.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/11/Article-09--1-.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>This table shows a few scenarios you may use to test your system. In these scenarios, you're testing how a monetary transfer of $20 changes the balance in different accounts.</figcaption></figure><p>Notice that in order to create these scenarios, you had to generate data: various starting balances ($500, $20, $10) as well as a transfer amount ($20). This is an early version of using fake data in order to test your software!</p><p><strong>Using Tools for Manual Creation</strong></p><p>Now let's fast forward in time. Over the years, your software has gotten even more complex, and you're constantly adding new functionalities. For example, maybe you start allowing transfers with foreign currency. </p><p>You need to test these functionalities before you roll them out. To save time, you might end up using -- or creating -- a tool that allows you to generate and manage fake data for testing. </p><p>The simplest tool may be a basic permutation, as illustrated below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-07-2.png\" class=\"kg-image\" alt=\"A simple manual test data generation tool that uses permutations. The resulting scenarios -- with different starting balances, transfer amounts and transfer currencies -- are outputted as a data table.\" loading=\"lazy\" width=\"1723\" height=\"809\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-07-2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-07-2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-07-2.png 1600w, https://sdv.ghost.io/content/images/2021/11/Article-07-2.png 1723w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A simple manual test data generation tool that uses permutations. The resulting scenarios -- with different starting balances, transfer amounts and transfer currencies -- are outputted as a data table.</figcaption></figure><p>A more sophisticated tool might allow you greater control over the rules the data must follow. It will also allow you to create more columns as your functionalities increase. For example, maybe the bank now offers two different account types: Premium and Normal. </p><p>Now you need a test data generation tool that can handle all of these variables and come out with something like this:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-11.png\" class=\"kg-image\" alt=\"A more sophisticated test data tool will allow you to specify rules manually. It will follow them to generate test data.\" loading=\"lazy\" width=\"1955\" height=\"655\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-11.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-11.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-11.png 1600w, https://sdv.ghost.io/content/images/2021/11/Article-11.png 1955w\" sizes=\"(min-width: 720px) 720px\"><figcaption>A more sophisticated test data tool will allow you to specify rules manually. It will follow them to generate test data.</figcaption></figure><p>Many test data management tools use sophisticated logic to precisely create these data columns and their values. But the rules they use are manually written, and rely on human intuition and domain knowledge. For example:</p><ul><li>Account type = Premium 10% of the time and Normal 90% of the time</li><li>Starting balance is between $10,000 and $250,000 if Account type = Premium<br>or between -$1,000 and $10,000 if Account type = Normal</li><li>Transfer amount follows a bell curve with a mean of $7,500 and standard deviation of $1,000</li><li>Etc.</li></ul><p>There are downsides to this manual approach. It takes time and effort to come up with these rules, to keep track of them, and to update them as your application changes.</p><h3 id=\"adding-machine-learning\">Adding Machine Learning</h3><p>Adopting machine learning (ML) opens up entirely new avenues in data generation. In the process, it gets rid of some of these downsides.</p><p>At a high level, ML-based software (such as the <a href=\"https://sdv.dev/blog/intro-to-sdv/\">Synthetic Data Vault</a>) works in three steps:</p><ol><li>The user inputs real data into the ML software</li><li>The ML software automatically learns patterns in the data</li><li>The software outputs data that contains those patterns</li></ol><p>Let's go back to our banking example to see how this works. It's now 2021 and you're using <a href=\"https://sdv.dev/\">the SDV</a> to generate your test data. You input all the transactions your bank has handled in the last week. </p><p>After modeling, the SDV outputs entirely new data that looks and behaves like the original. An illustration of this is shown below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-10.png\" class=\"kg-image\" alt=\"With ML tools (like the SDV), you input real data into the software. The software then learns patterns from the data and outputs data that matches those patterns.\" loading=\"lazy\" width=\"2000\" height=\"516\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-10.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-10.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/11/Article-10.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/11/Article-10.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>With ML tools (like the SDV), you input real data into the software. The software then learns patterns from the data and outputs data that matches those patterns.</figcaption></figure><p>Notice that the output data contains many of the same properties as the original. The model learned all of the following information:</p><ul><li><strong>Ranges &amp; Categories.</strong> Transfers range from $5K to $10K. Bank accounts can be either premium or normal. Etc.</li><li><strong>Shapes.</strong> 10% of accounts are premium. Transfers follow a bell curve distribution with a mean of $7,500 and a standard deviation of $1,000. Etc.</li><li><strong>Correlations.</strong> Premium bank accounts tend to have higher balances ($10K to $250K) than normal accounts (-$1K to $10K).</li></ul><p>In other words: <strong>while the old test data management tools required you to manually come up with rules, ML-based tools learn these rules automatically.</strong> <strong> </strong>Moreover, they can learn new information. For example, the ML picked upon a couple of extra correlations:</p><ul><li>Premium accounts are more likely to transfer foreign currency.</li><li>Normal accounts are more likely to be overdrawn (transfer more than their current balance).</li></ul><p>Using an ML-based data generation tool will help you ensure that your software is robust against these typical cases. And while manual data generation tools generate fake data, <strong>ML-based approaches generate what we call synthetic data.</strong></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/11/Article-08-1.png\" class=\"kg-image\" alt=\"Ask whether you had to input any real data or rules. Based on this, you'll know whether you are dealing with synthetic data or fake data.\" loading=\"lazy\" width=\"1574\" height=\"419\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/11/Article-08-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/11/Article-08-1.png 1000w, https://sdv.ghost.io/content/images/2021/11/Article-08-1.png 1574w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Ask whether you had to input any real data or rules. Based on this, you'll know whether you are dealing with synthetic data or fake data.</figcaption></figure><p><strong>Benefits of Synthetic Data</strong></p><p>There are some clear advantages to using synthetic data over fake data, especially in software testing. Below, we've detailed a few.</p><ul><li><strong>Saves time with automation.</strong> Because ML automatically learns patterns from the real data, there is no need to spend a lot of time coming up with and inputting rules. ML learns rules that you may even miss.</li><li><strong>Is usable by non-experts. </strong>Realistic fake data can only be generated by domain experts, who know the precise rules governing the dataset. However, anyone can generate synthetic data. All they have to do is input the real data and the ML software takes care of the rest!</li><li><strong>Increases adaptability. </strong>Applications and data will inevitably change over time. It's easy to update synthetic data as this happens, simply by retraining the ML model with newer data.</li></ul><p>Benefits of synthetic data expand beyond software testing. The SDV Community is using synthetic data for an ever-increasing variety of tasks, including machine learning development, de-biasing datasets and scenario planning.</p><h3 id=\"key-takeaways\">Key Takeaways</h3><p>In this article, we surveyed numerous ways of creating and using data  that is not real. In particular, we learned that:</p><ul><li>Creating fake data is not a novel concept. Older generations of tools will output fake data when given an explicit list of rules. This is especially useful for software testing.</li><li>Adding ML to this process is a newer evolution. Users input real data into the ML model, and it's able to automatically infer the rules. Data generated using ML-based systems is known as <strong>synthetic data</strong>.</li><li>Synthetic data's key advantages include its automation and adaptability. The uses of synthetic data expand beyond software testing.</li></ul><p>In future articles, we'll put ML models to the test! We'll uncover their strengths and weaknesses, and guide you through getting the most from synthetic data using the Synthetic Data Vault.</p>","url":"https://sdv.ghost.io/fake-to-synthetic-ml/","canonical_url":null,"uuid":"b2a72ccc-d24f-42ad-90fb-23d0017e2529","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"61927ca167598b003b3d944a","reading_time":6}},{"node":{"id":"Ghost__Post__609c384488b3f9003e080016","title":"Your Feedback in Action, Part 2: Data Workflow","slug":"community-feedback-workflow","featured":false,"feature_image":"https://sdv.ghost.io/content/images/2021/05/Banner-2-1.png","excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","custom_excerpt":"After thousands of downloads, see how the synthetic data workflow in the SDV has evolved based on feedback from users.","visibility":"public","created_at_pretty":"12 May, 2021","published_at_pretty":"19 May, 2021","updated_at_pretty":"19 May, 2021","created_at":"2021-05-12T16:19:16.000-04:00","published_at":"2021-05-19T12:52:14.000-04:00","updated_at":"2021-05-19T12:52:14.000-04:00","meta_title":"Improving synthetic data workflows","meta_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Based on feedback from real users, SDV has evolved workflows around generating synthetic data. Learn about transformations, conditional sampling, and evaluation.","twitter_image":null,"twitter_title":null,"authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"The Synthetic Data Vault (SDV) is a software system that allows users all over\nthe world to input a dataset and generate synthetic data. The SDV was born out\nof academic research at MIT — but in 2018, we open-sourced it, so that people\nall over the world could use it.\n\nSince then, we've been listening carefully to our community's feedback, making\nsure that we address any gaps between theoretical academic research and\npractical use. This article is the second in a multi-part series detailing\nrecent improvements to the SDV that make it work in the real world. Here we'll\ndiscuss how we've amped up the data synthesis workflow. (For our previous\ndiscussion about how we've improved core models, see Part 1\n[http://sdv.dev/blog/community-feedback-models].)\n\nWhat are workflows?\nWe open sourced the SDV not just to let users generate synthetic data, but also\nto allow them use that data to solve real-world problems. Our community taught\nus that actually using the SDV involves a multi-step process — and that\nimproving the system means paying attention to this entire workflow, not just\nthe core machine learning.\n\nAccording to our users, this workflow boils down to a few generalizable steps:\n\n 1. Identifying real datasets that need to be synthesized\n 2. Transforming the datasets into a machine-readable format\n 3. Running the machine learning model\n 4. Synthesizing data according to particular specifications\n 5. Reversing the transformations such that the synthesized data looks like the\n    original\n 6. Evaluating the synthesized data that results\n\nThese steps are illustrated in the diagram below.\n\nThe entire synthetic data workflow involves more than just modeling. Data also\nneeds to be transformed, synthesized, reverse transformed, and evaluated.The key\ninsight from our users was that the application of machine learning models is\nonly one step of a much larger puzzle. When the open source community helped us\nunderstand this, we were able to improve on the SDV software by adding in\ntransformations, synthesizing options, and evaluation tools -- all detailed\nbelow.\n\nTransforming Data\nOne major lesson from our open source community was how messy real-world\ndatasets are compared to those used in academia. Academic datasets often come\npre-sanitized and ready for numerical use. In the real world, however, databases\nare growing and changing constantly, and are often significantly different from\nthe optimal yet theoretical structures used by machine learning researchers.\n\nTwo thorny data types frequently encountered in the real world are datetimes and \nnull values.\n\n * Datetimes can follow many different formats, including YYYY-MM-DD or\n   MM-DD-YY. However, machine learning models accept numerical values only.\n   Usually these are Unix timestamps, defined as the number of seconds that have\n   elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will\n   transform into the number 1609488000.\n * Null values also present a problem for mathematical models when they appear\n   in numerical data. While users can tell models to ignore these values, the\n   presence of a null might actually indicate something important, like a user\n   declining to answer a question. To account for this, the SDV creates a new,\n   binary column to address whether the original value is null.\n\nWhen working with real-world datasets, it's necessary to apply transformations\nbetween real data and machine-readable data. This example transforms datetimes\nand null values.To solve this problem, we introduced a new library called Reversible Data\nTransforms [https://github.com/sdv-dev/RDT] (RDT). The RDT library contains\nnecessary logic for transforming different types of real world data to its\nmachine-ready counterpart — as well as the logic for its reversal, so that a\nsynthetic data user won't know the difference. The RDT is a standalone library\nthat can reach beyond the synthetic data space, helping data scientists and\nacademics across fields to clean their data. Since November 2020, the RDT has\nbeen supported on all major platforms including MacOS, Windows, and Linux.\n\nSynthesizing Data Conditionally\nWhen we first imagined the SDV, we assumed users would simply want to use all\nthe synthetic data generated by the model. However, we soon found that some\nusers have more complex needs, and require more control over the data they\nsynthesize — opening up new possibilities for synthetic data in the process.\n\nFor example, one of our users, an engineer, found a whole new use for SDV. The\nengineer was writing a machine learning classifier on a dataset when they\nnoticed it was unbalanced. Applying any algorithms to this dataset would lead to\nbiased models. The engineer realized that, if used strategically, SDV could\nactually debias the data — if it only generated data with rarer attributes, the\nsynthetic data it created could be combined with the real data to form a fully\nbalanced dataset.\n\nSynthesized data can help remove bias by creating balanced datasets. In this\nexample, synthesizing those rows that only correspond to females creates a\nbalance between males and females.In February of 2021, we added conditional sampling\n[https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling] \nto the SDV to enable this use case. Now, users can specify attributes or values\nthat must be present in the synthesized data. In addition to debiasing datasets,\nusers can use this feature to test hypothetical scenarios.\n\nEvaluating Synthesized Data\nWhen the entire system is working smoothly and outputting synthetic data, users\nstill need to know: Is the data good enough to use? This vital question inspired\nus to add evaluation capabilities to the SDV. In doing so, we faced two key\nchallenges: Defining the metrics, and creating a useful process.\n\nMetrics\n\nNo single metric perfectly captures the different dimensions of synthetic data\nusers may want to evaluate. Some want to preserve a high degree of mathematical\nlikeness, others want to emphasize a particular column for machine learning\npredictions, and still others are more focused on threat models that can\ncompromise privacy. \n\nTo address this, we created a separate library, SDMetrics\n[https://github.com/sdv-dev/SDMetrics], to define evaluation metrics. The\nlibrary now includes a suite of metrics that cover differentiation of synthetic\nand real data, statistical likeness, and privacy.\n\nApplication\n\nRather than apply metrics on an ad-hoc basis, some SDV power users were creating\nmini-workflows to rapidly test out different models, datasets and evaluation\ncriteria in succession. Inspired by their innovation, we created SDGym\n[https://github.com/sdv-dev/SDGym], a system that allows users to input models,\ndatasets and success metrics to build a comprehensive evaluation framework.\n\nThe SDV Software Today\nThe SDV software is continuously evolving based on community feedback. In this\narticle, we discussed improvements to the workflow surrounding synthetic data\ngeneration, including data transformations, sampling methods and evaluation\ntools. Earlier, in Part 1 [https://sdv.dev/blog/community-feedback-models] of\nthis series, we discussed the core synthetic data models themselves. In future\nblog articles, we plan to dig deeper into each of these areas, and to uncover\nnew ones with you.\n\nLike the SDV, this blog is a collaborative effort. Use our Slack\n[https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw] \nto let us know which topics you'd like to hear more about. And as always, use \nGitHub [https://github.com/sdv-dev/SDV] to file technical issues with the\nsystem. Working together, we can make SDV the most trusted, transparent and\ncomprehensive platform for synthetic data generation!\n\nFor other inquiries, please contact info@sdv.dev [ info@sdv.dev].","html":"<p>The Synthetic Data Vault (SDV) is a software system that allows users all over the world to input a dataset and generate synthetic data. The SDV was born out of academic research at MIT — but in 2018, we open-sourced it, so that people all over the world could use it.</p><p>Since then, we've been listening carefully to our community's feedback, making sure that we address any gaps between theoretical academic research and practical use. This article is the second in a multi-part series detailing recent improvements to the SDV that make it work in the real world. Here we'll discuss how we've amped up the data synthesis workflow. (For our previous discussion about how we've improved core models, see <a href=\"http://sdv.dev/blog/community-feedback-models\">Part 1</a>.)</p><h3 id=\"what-are-workflows\">What are workflows?</h3><p>We open sourced the SDV not just to let users generate synthetic data, but also to allow them <em>use</em> that data to solve real-world problems. Our community taught us that actually using the SDV involves a multi-step process — and that improving the system means paying attention to this entire workflow, not just the core machine learning.</p><p>According to our users, this workflow boils down to a few generalizable steps:</p><ol><li>Identifying real datasets that need to be synthesized</li><li>Transforming the datasets into a machine-readable format</li><li>Running the machine learning model</li><li>Synthesizing data according to particular specifications</li><li>Reversing the transformations such that the synthesized data looks like the original</li><li>Evaluating the synthesized data that results</li></ol><p>These steps are illustrated in the diagram below.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----1.png\" class=\"kg-image\" alt=\"An illustration of the synthetic data workflow: Transforming data, modeling, synthesizing, reverse transforming, and evaluating.\" loading=\"lazy\" width=\"2000\" height=\"1106\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----1.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/05/Community-Feedback--Part-2----1.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>The entire synthetic data workflow involves more than just modeling. Data also needs to be transformed, synthesized, reverse transformed, and evaluated.</figcaption></figure><p>The key insight from our users was that the application of machine learning models is only one step of a much larger puzzle. When the open source community helped us understand this, we were able to improve on the SDV software by adding in transformations, synthesizing options, and evaluation tools -- all detailed below.</p><h3 id=\"transforming-data\">Transforming Data</h3><p>One major lesson from our open source community was how messy real-world datasets are compared to those used in academia. Academic datasets often come pre-sanitized and ready for numerical use. In the real world, however, databases are growing and changing constantly, and are often significantly different from the optimal yet theoretical structures used by machine learning researchers.</p><p>Two thorny data types frequently encountered in the real world are <em>datetimes</em> and <em>null values</em>.</p><ul><li><strong>Datetimes</strong> can follow many different formats, including YYYY-MM-DD or MM-DD-YY. However, machine learning models accept numerical values only. Usually these are Unix timestamps, defined as the number of seconds that have elapsed since January 1, 1970. By this logic, a date like 2021-01-01 will transform into the number 1609488000.</li><li><strong>Null values</strong> also present a problem for mathematical models when they appear in numerical data. While users can tell models to ignore these values, the presence of a null might actually indicate something important, like a user declining to answer a question. To account for this, the SDV creates a new, binary column to address whether the original value is null.</li></ul><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png\" class=\"kg-image\" alt=\"Two tables showing data in its original and transformed formats. The original format includes a human-readable date column and a weight column that can be null.\" loading=\"lazy\" width=\"2000\" height=\"754\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----2-1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----2-1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----2-1.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----2-1.png 2280w\" sizes=\"(min-width: 720px) 720px\"><figcaption>When working with real-world datasets, it's necessary to apply transformations between real data and machine-readable data. This example transforms datetimes and null values.</figcaption></figure><p>To solve this problem, we introduced a new library called <a href=\"https://github.com/sdv-dev/RDT\">Reversible Data Transforms</a> (RDT). The RDT library contains necessary logic for transforming different types of real world data to its machine-ready counterpart — as well as the logic for its reversal, so that a synthetic data user won't know the difference. The RDT is a standalone library that can reach beyond the synthetic data space, helping data scientists and academics across fields to clean their data. Since November 2020, the RDT has been supported on all major platforms including MacOS, Windows, and Linux.</p><h3 id=\"synthesizing-data-conditionally\">Synthesizing Data Conditionally</h3><p>When we first imagined the SDV, we assumed users would simply want to use all the synthetic data generated by the model. However, we soon found that some users have more complex needs, and require more control over the data they synthesize — opening up new possibilities for synthetic data in the process.</p><p>For example, one of our users, an engineer, found a whole new use for SDV. The engineer was writing a machine learning classifier on a dataset when they noticed it was unbalanced. Applying any algorithms to this dataset would lead to biased models. The engineer realized that, if used strategically, SDV could actually debias the data — if it only generated data with rarer attributes, the synthetic data it created could be combined with the real data to form a fully balanced dataset.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png\" class=\"kg-image\" alt=\"Biased data that contains more males, plus synthesized data with only females, combines to form a balanced dataset with both males and females.\" loading=\"lazy\" width=\"1705\" height=\"960\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-2----3.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-2----3.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-2----3.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-2----3.png 1705w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Synthesized data can help remove bias by creating balanced datasets. In this example, synthesizing those rows that only correspond to females creates a balance between males and females.</figcaption></figure><p>In February of 2021, we added <a href=\"https://sdv.dev/SDV/user_guides/single_table/gaussian_copula.html#conditional-sampling\">conditional sampling</a> to the SDV to enable this use case. Now, users can specify attributes or values that must be present in the synthesized data. In addition to debiasing datasets, users can use this feature to test hypothetical scenarios.</p><h3 id=\"evaluating-synthesized-data\">Evaluating Synthesized Data</h3><p>When the entire system is working smoothly and outputting synthetic data, users still need to know: Is the data good enough to use? This vital question inspired us to add evaluation capabilities to the SDV. In doing so, we faced two key challenges: Defining the metrics, and creating a useful process<strong>.</strong></p><p><strong>Metrics</strong></p><p>No single metric perfectly captures the different dimensions of synthetic data users may want to evaluate. Some want to preserve a high degree of mathematical likeness, others want to emphasize a particular column for machine learning predictions, and still others are more focused on threat models that can compromise privacy. </p><p>To address this, we created a separate library, <a href=\"https://github.com/sdv-dev/SDMetrics\">SDMetrics</a>, to define evaluation metrics. The library now includes a suite of metrics that cover differentiation of synthetic and real data, statistical likeness, and privacy.</p><p><strong>Application</strong></p><p>Rather than apply metrics on an ad-hoc basis, some SDV power users were creating mini-workflows to rapidly test out different models, datasets and evaluation criteria in succession. Inspired by their innovation, we created <a href=\"https://github.com/sdv-dev/SDGym\">SDGym</a>, a system that allows users to input models, datasets and success metrics to build a comprehensive evaluation framework.</p><h3 id=\"the-sdv-software-today\">The SDV Software Today</h3><p>The SDV software is continuously evolving based on community feedback. In this article, we discussed improvements to the workflow surrounding synthetic data generation, including data transformations, sampling methods and evaluation tools. Earlier, in <a href=\"https://sdv.dev/blog/community-feedback-models\">Part 1</a> of this series, we discussed the core synthetic data models themselves. In future blog articles, we plan to dig deeper into each of these areas, and to uncover new ones with you.</p><p>Like the SDV, this blog is a collaborative effort. Use our <a href=\"https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw\">Slack</a> to let us know which topics you'd like to hear more about. And as always, use <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a> to file technical issues with the system. Working together, we can make SDV the most trusted, transparent and comprehensive platform for synthetic data generation!</p><p><em>For other inquiries, please contact <a href=\"mailto: info@sdv.dev\">info@sdv.dev</a>.</em><br></p>","url":"https://sdv.ghost.io/community-feedback-workflow/","canonical_url":"https://sdv.dev/blog/community-feedback-workflow","uuid":"b55a798b-c1d5-4851-995d-d4b5931184b8","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"609c384488b3f9003e080016","reading_time":5}},{"node":{"id":"Ghost__Post__609c351b88b3f9003e07ffb8","title":"Your Feedback in Action, Part 1: Data Models","slug":"community-feedback-models","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2021/05/Banner-2.png","excerpt":"After thousands of downloads, see how SDV's machine learning models have evolved based on feedback from users.","custom_excerpt":"After thousands of downloads, see how SDV's machine learning models have evolved based on feedback from users.","visibility":"public","created_at_pretty":"12 May, 2021","published_at_pretty":"12 May, 2021","updated_at_pretty":"23 June, 2021","created_at":"2021-05-12T16:05:47.000-04:00","published_at":"2021-05-12T16:15:30.000-04:00","updated_at":"2021-06-23T10:02:10.000-04:00","meta_title":"Improving machine learning for synthetic data","meta_description":"Based on feedback from real users, SDV's machine learning models have evolved to offer more choices, understand sequential data, and encode business logic.","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Based on feedback from real users, SDV's machine learning models have evolved to offer more choices, understand sequential data, and encode business logic.","twitter_image":null,"twitter_title":"Improving machine learning for synthetic data","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Product","slug":"product","description":"This blog focuses on the value that synthetic data brings to business. Our users have successfully used the SDV to augment datasets, test applications, remove bias and more. Explore new use cases, concepts and case studies.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"In our last post [https://sdv.dev/blog/intro-to-sdv/], we introduced the \nSynthetic Data Vault [https://github.com/sdv-dev/SDV] (SDV) — a software system\nthat allows users to input a dataset and generate synthetic data. The SDV was\nborn out of academic research at MIT — but in 2018, we open-sourced it, so that\npeople all over the world could use it.\n\nSince then, we've been listening carefully to our community's feedback, making\nsure that we address any gaps between theoretical academic research and\npractical use. This multi-part series details recent improvements we've made so\nthat SDV works in the real world. In this article, we focus on the machine\nlearning-based modeling techniques that form the core of the system, while Part\n2 [https://sdv.dev/blog/community-feedback-workflow/] will cover the surrounding\nworkflow.\n\nWhat's in a model?\nAt its core, the SDV is a set of machine learning models designed to understand\nand mimic real world data. Once the SDV creates a particular model, developers\ncan generate synthetic data by sampling it. For synthetic data to be successful,\nthis generative model must be correct — but through discussions with our open\nsource community, we realized that there is no such thing as a single, winning\napproach that works every time. Each dataset and use case is different.\n\n\nOur solution is to provide choices, giving users all the necessary tools to make\nuseful synthetic data for each new case at hand. Let's dive into three popular\nuses of the SDV where such options are available: Tabular models, sequential\ndata and business logic.\n\nMore Options for Tabular Models\nThe earliest version of SDV was based on a classic statistical method: Gaussian\nCopulas [https://en.wikipedia.org/wiki/Copula_(probability_theory)]. This model\nis transparent by definition. It allows us to understand and exert control over\nformulas in the model, notably the distributions of each variable. This can be\nespecially useful for business applications, where data often follows\npredictable distributions. For example, wind speed is known to follow a Weibull\ndistribution [https://en.wikipedia.org/wiki/Wind_power], biological measures\nlike height usually follow normal distributions\n[https://en.wikipedia.org/wiki/Normal_distribution#Occurrence_and_applications] \nand credit default rates often follow exponential distributions\n[https://en.wikipedia.org/wiki/Exponential_distribution].\n\nMeanwhile, advances in the AI space had also produced a robust, alternative\nmodel for those willing to sacrifice transparency: A deep learning technique\ncalled Generative Adversarial Networks\n[https://en.wikipedia.org/wiki/Generative_adversarial_network] (GANs). GANs\nmodel complex processes that don't follow known formulas. While these models’\ninner workings aren’t easily explained by humans, they produce highly accurate\nresults. We created a GAN, called CTGAN, specifically for synthetic data. This\nblack box model is especially good at figuring out complex correlations between\nvariables in large datasets.\n\nFor a long time, SDV allowed users a choice between our Gaussian Copulas based\nmodel, called GaussianCopula, and CTGAN to model tabular data. While this choice\nprovided some flexibility, our users reported they had a hard time choosing\nbetween such extreme alternatives. We wondered if a middle ground was possible:\nCould we specify distributions while also using GANs to identify complex\ncorrelations?\n\nWe couldn't find any model that fit both of these requirements, so we made our\nown! A key insight was that we could use Gaussian Copulas to understand the data\nand transform it before applying it to a GAN. The result is CopulaGAN\n[https://sdv.dev/SDV/user_guides/single_table/copulagan.html], a hybrid model we\nreleased in October 2020.\n\nCopulaGAN is in the middle of the spectrum, between simple, easily understood\nmodels (like GaussianCopula) and complex black box models (like CTGAN).CopulaGAN\ncombines the human accessibility of Gaussian Copulas with the robust accuracy of\nGANs. This innovation provides users with a new choice: a hybrid approach.\n\nThe Special Case of Sequential Data\nAnother tricky case pointed out by our users involved sequential data. While\nsequential data is stored in a table, it is unlike a regular table in that its\nrows are linked together, usually by a time component. This use case is\nextremely frequent, especially in finance — any table with credit card\ntransactions, stock prices, or payments is almost certainly sequential. \n\nAt the time, solutions treated sequential data as a case of general tabular\nmodeling. After all, sequential data is inside a table. However, these solutions\nfailed to incorporate the key information that makes sequential data unique: The\nrelationships that exist between rows.\n\nIn this table of stock prices, rows that describe the same company — in this\ncase, Google — are related to each other through time. Related rows are a\nspecial feature of sequential datasets.While considering this pain point, we\nrecognized sequential data as an entirely new case that required its own unique\nset of modeling techniques. In October 2020, we released our DeepEcho library,\nwhich focuses entirely on sequential data. We also introduced our PAR model:\n[https://sdv.dev/SDV/user_guides/timeseries/par.html] a GAN approach made\nspecifically for sequential data.\n\nEncoding Business Logic using Constraints\nEven with a plethora of modeling choices, it's vital to capture nuances in\nbusiness logic while modeling synthetic data. This is due to differences in how\nhumans and machines understand datasets.\n\nOften, humans can easily glean the meaning of a dataset using context clues.\nConsider a table showing the names and ages of students and their legal\nguardians. A human will intuitively realize that a student must be younger than\ntheir guardian.\n\nIn this table of students and their guardians, the student is always younger\nthan their guardian. This is a constraint that humans intuitively understand.But\nwill a machine understand the same rule? Because all of the SDV's models use\nstatistics, they analyze trends generally — meaning that in this case, they will\ninclude a small possibility that a student could be older than their guardian.\nAfter all, is it totally out of the question that an older individual could\nenroll and list their child as their guardian? Either way, only a human expert\ncan truly figure out what makes sense for this dataset!\n\nTo solve this pain point, SDV introduced the concept of constraints\n[https://sdv.dev/SDV/user_guides/single_table/constraints.html] in July 2020.\nConstraints give users the ability to encode their business knowledge and\nexpertise into an SDV model. In our example, they could specify that a\nguardian's age must be greater than the student's. Currently, the GreaterThan\nand UniqueCombination constraints allow for easy handling of common scenarios.\nWe also provide a blanket CustomConstraint class, which gives users flexibility\nto capture more nuanced knowledge.\n\nMore Community Feedback\nWe believe that the more humans and machines can work together, the more\nefficient our processes can become. In this article, we explained how user\nfeedback about the SDV led to new core modeling techniques and innovations —\nenabling a system that now provides a choice of multiple models, handles\nsequential data, and understands constraints. In Part 2\n[https://sdv.dev/blog/community-feedback-workflow/], we will discuss similar\nfeedback-driven innovations in the rest of the workflow.\n\nUsing SDV — and giving us feedback — fuels this rapid evolution. To start a\ndiscussion, please message us on Slack\n[https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw] \nor file an issue on GitHub [https://github.com/sdv-dev/SDV]. Working together,\nwe can make SDV the most trusted, transparent and comprehensive platform for\nsynthetic data generation!\n\nFor other inquiries, please contact info@sdv.dev.","html":"<p>In our <a href=\"https://sdv.dev/blog/intro-to-sdv/\">last post</a>, we introduced the <a href=\"https://github.com/sdv-dev/SDV\">Synthetic Data Vault</a> (SDV) — a software system that allows users to input a dataset and generate synthetic data. The SDV was born out of academic research at MIT — but in 2018, we open-sourced it, so that people all over the world could use it.</p><p>Since then, we've been listening carefully to our community's feedback, making sure that we address any gaps between theoretical academic research and practical use. This multi-part series details recent improvements we've made so that SDV works in the real world. In this article, we focus on the machine learning-based modeling techniques that form the core of the system, while <a href=\"https://sdv.dev/blog/community-feedback-workflow/\">Part 2</a> will cover the surrounding workflow.</p><h3 id=\"whats-in-a-model\">What's in a model?</h3><p>At its core, the SDV is a set of machine learning models designed to understand and mimic real world data. Once the SDV creates a particular model, developers can generate synthetic data by sampling it. For synthetic data to be successful, this generative model must be correct — but through discussions with our open source community, we realized that there is no such thing as a single, winning approach that works every time. Each dataset and use case is different.<br></p><p>Our solution is to provide choices, giving users all the necessary tools to make useful synthetic data for each new case at hand. Let's dive into three popular uses of the SDV where such options are available: Tabular models, sequential data and business logic.</p><h3 id=\"more-options-for-tabular-models\">More Options for Tabular Models</h3><p>The earliest version of SDV was based on a classic statistical method: <a href=\"https://en.wikipedia.org/wiki/Copula_(probability_theory)\">Gaussian Copulas</a>. This model is transparent by definition. It allows us to understand and exert control over formulas in the model, notably the distributions of each variable. This can be especially useful for business applications, where data often follows predictable distributions. For example, wind speed is known to follow a <a href=\"https://en.wikipedia.org/wiki/Wind_power\">Weibull distribution</a>, biological measures like height usually follow <a href=\"https://en.wikipedia.org/wiki/Normal_distribution#Occurrence_and_applications\">normal distributions</a> and credit default rates often follow <a href=\"https://en.wikipedia.org/wiki/Exponential_distribution\">exponential distributions</a>.</p><p>Meanwhile, advances in the AI space had also produced a robust, alternative model for those willing to sacrifice transparency: A deep learning technique called <a href=\"https://en.wikipedia.org/wiki/Generative_adversarial_network\">Generative Adversarial Networks</a> (GANs). GANs model complex processes that don't follow known formulas. While these models’ inner workings aren’t easily explained by humans, they produce highly accurate results. We created a GAN, called CTGAN, specifically for synthetic data. This black box model is especially good at figuring out complex correlations between variables in large datasets.</p><p>For a long time, SDV allowed users a choice between our Gaussian Copulas based model, called GaussianCopula, and CTGAN to model tabular data. While this choice provided some flexibility, our users reported they had a hard time choosing between such extreme alternatives. We wondered if a middle ground was possible: Could we specify distributions while also using GANs to identify complex correlations?</p><p>We couldn't find any model that fit both of these requirements, so we made our own! A key insight was that we could use Gaussian Copulas to understand the data and transform it before applying it to a GAN. The result is <a href=\"https://sdv.dev/SDV/user_guides/single_table/copulagan.html\">CopulaGAN</a>, a hybrid model we released in October 2020.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----1.png\" class=\"kg-image\" alt=\"A diagram showing a scale of simple human accessible models (GaussianCopula) versus complex black box models (like CTGAN), with CopulaGAN is in the middle.\" loading=\"lazy\" width=\"2000\" height=\"695\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-1----1.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-1----1.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-1----1.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----1.png 2100w\" sizes=\"(min-width: 720px) 720px\"><figcaption>CopulaGAN is in the middle of the spectrum, between simple, easily understood models (like GaussianCopula) and complex black box models (like CTGAN).</figcaption></figure><p>CopulaGAN combines the human accessibility of Gaussian Copulas with the robust accuracy of GANs. This innovation provides users with a new choice: a hybrid approach.</p><h3 id=\"the-special-case-of-sequential-data\">The Special Case of Sequential Data</h3><p>Another tricky case pointed out by our users involved sequential data. While sequential data is stored in a table, it is unlike a regular table in that its rows are linked together, usually by a time component. This use case is extremely frequent, especially in finance — any table with credit card transactions, stock prices, or payments is almost certainly sequential. </p><p>At the time, solutions treated sequential data as a case of general tabular modeling. After all, sequential data is inside a table. However, these solutions failed to incorporate the key information that makes sequential data unique: The relationships that exist between rows.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----2.png\" class=\"kg-image\" alt=\"A table that shows sequential, time series data of daily stock prices corresponding to different companies.\" loading=\"lazy\" width=\"1840\" height=\"1210\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-1----2.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-1----2.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-1----2.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----2.png 1840w\" sizes=\"(min-width: 720px) 720px\"><figcaption>In this table of stock prices, rows that describe the same company — in this case, Google — are related to each other through time. Related rows are a special feature of sequential datasets.</figcaption></figure><p>While considering this pain point, we recognized sequential data as an entirely new case that required its own unique set of modeling techniques. In October 2020, we released our DeepEcho library, which focuses entirely on sequential data. We also introduced our <a href=\"https://sdv.dev/SDV/user_guides/timeseries/par.html\">PAR model:</a> a GAN approach made specifically for sequential data.</p><h3 id=\"encoding-business-logic-using-constraints\">Encoding Business Logic using Constraints</h3><p>Even with a plethora of modeling choices, it's vital to capture nuances in business logic while modeling synthetic data. This is due to differences in how humans and machines understand datasets.</p><p>Often, humans can easily glean the meaning of a dataset using context clues. Consider a table showing the names and ages of students and their legal guardians. A human will intuitively realize that a student must be younger than their guardian.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----3.png\" class=\"kg-image\" alt=\"A table of student names, their ages, their guardians, and the guardians' ages.\" loading=\"lazy\" width=\"2000\" height=\"969\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/05/Community-Feedback--Part-1----3.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/05/Community-Feedback--Part-1----3.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/05/Community-Feedback--Part-1----3.png 1600w, https://sdv.ghost.io/content/images/2021/05/Community-Feedback--Part-1----3.png 2230w\" sizes=\"(min-width: 720px) 720px\"><figcaption>In this table of students and their guardians, the student is always younger than their guardian. This is a constraint that humans intuitively understand.</figcaption></figure><p>But will a machine understand the same rule? Because all of the SDV's models use statistics, they analyze trends generally — meaning that in this case, they will include a small possibility that a student could be older than their guardian. After all, is it totally out of the question that an older individual could enroll and list their child as their guardian? Either way, only a human expert can truly figure out what makes sense for this dataset!</p><p>To solve this pain point, SDV introduced the concept of <a href=\"https://sdv.dev/SDV/user_guides/single_table/constraints.html\">constraints</a> in July 2020. Constraints give users the ability to encode their business knowledge and expertise into an SDV model. In our example, they could specify that a guardian's age must be greater than the student's. Currently, the GreaterThan and UniqueCombination constraints allow for easy handling of common scenarios. We also provide a blanket CustomConstraint class, which gives users flexibility to capture more nuanced knowledge.</p><h3 id=\"more-community-feedback\">More Community Feedback</h3><p>We believe that the more humans and machines can work together, the more efficient our processes can become. In this article, we explained how user feedback about the SDV led to new core modeling techniques and innovations — enabling a system that now provides a choice of multiple models, handles sequential data, and understands constraints. In <a href=\"https://sdv.dev/blog/community-feedback-workflow/\">Part 2</a>, we will discuss similar feedback-driven innovations in the rest of the workflow.</p><p>Using SDV — and giving us feedback — fuels this rapid evolution. To start a discussion, please message us on <a href=\"https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw\">Slack</a> or file an issue on <a href=\"https://github.com/sdv-dev/SDV\">GitHub</a>. Working together, we can make SDV the most trusted, transparent and comprehensive platform for synthetic data generation!</p><p><em>For other inquiries, please contact <strong>info@sdv.dev</strong>.</em><br></p>","url":"https://sdv.ghost.io/community-feedback-models/","canonical_url":null,"uuid":"b07a410f-1cf1-45f1-a82e-e66cfdaf61b9","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"609c351b88b3f9003e07ffb8","reading_time":5}},{"node":{"id":"Ghost__Post__608c5562f9741d003b6f73b8","title":"Meet the Synthetic Data Vault","slug":"intro-to-sdv","featured":true,"feature_image":"https://sdv.ghost.io/content/images/2021/05/blog-header--1-.png","excerpt":"Welcome to the SDV Blog! The SDV is a comprehensive, open source software for synthetic data generation. Join our growing community as we create an ecosystem to solve real world problems!","custom_excerpt":"Welcome to the SDV Blog! The SDV is a comprehensive, open source software for synthetic data generation. Join our growing community as we create an ecosystem to solve real world problems!","visibility":"public","created_at_pretty":"30 April, 2021","published_at_pretty":"04 May, 2021","updated_at_pretty":"05 May, 2021","created_at":"2021-04-30T15:07:14.000-04:00","published_at":"2021-05-04T09:00:00.000-04:00","updated_at":"2021-05-04T20:08:55.000-04:00","meta_title":"Meet the Synthetic Data Vault","meta_description":"Check out our new blog introducing MIT’s Synthetic Data Vault. Join us for discussions on synthetic data, our libraries and the industry!","og_description":null,"og_image":null,"og_title":null,"twitter_description":"Check out our new blog introducing MIT’s Synthetic Data Vault. Join us for discussions on synthetic data, our libraries and the industry!","twitter_image":null,"twitter_title":"Meet the Synthetic Data Vault","authors":[{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},{"name":"Carles Sala","slug":"carles","bio":"Carles is a seasoned ML and Software Engineer, and former researcher at MIT, where he led the development efforts to grow the SDV prototype into the successful open source project that it is today.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Carles_Sala.jpg","twitter":"@csalacat","facebook":null,"website":"https://csala.dev/"}],"primary_author":{"name":"Neha Patki","slug":"neha","bio":"Neha first created the SDV for her Master's thesis at MIT and also has experience in Product Management from Google. She is excited to use her expertise to build a great SDV user experience.","profile_image":"https://sdv.ghost.io/content/images/2021/05/Neha_Patki--1-.jpg","twitter":"@n4atki","facebook":null,"website":"https://www.linkedin.com/in/nehapatki/"},"primary_tag":{"name":"Project","slug":"project","description":"We want the SDV to be the most trusted, transparent and comprehensive platform for synthetic data generation. Join our journey as we share updates about the SDV strategy and leadership.","feature_image":null,"meta_description":"The Synthetic Data Vault Project is a growing ecosystem of open source libraries & resources for generating synthetic data for different data modalities.","meta_title":"Synthetic Data Vault Project","visibility":"public"},"tags":[{"name":"Project","slug":"project","description":"We want the SDV to be the most trusted, transparent and comprehensive platform for synthetic data generation. Join our journey as we share updates about the SDV strategy and leadership.","feature_image":null,"meta_description":"The Synthetic Data Vault Project is a growing ecosystem of open source libraries & resources for generating synthetic data for different data modalities.","meta_title":"Synthetic Data Vault Project","visibility":"public"}],"plaintext":"Hello world! We, the creators of MIT's Synthetic Data Vault, warmly welcome you\nto our official blog. Soon we'll be using this space to deep-dive into topics\nrelated to our libraries, and to unpack ideas in the synthetic data space. We're\nlooking forward to exploring this exciting area with you.\n\nBut first, we want to properly introduce our project: The Synthetic Data Vault\n[https://github.com/sdv-dev/SDV] (SDV), an open source software ecosystem for\ngenerating synthetic data. In this post, we’ll explain why synthetic data is\nimportant, and tell the story of how we created the vault. We’ll also lay out\nwhat’s in store — and how you can get involved. Let’s get started with a brief\noverview.\n\nSynthetic Data What?\nSynthetic data is a bold new frontier in machine learning. It allows developers\nto share and use data more effectively.\n\nIt may seem counterintuitive, but although billions of gigabytes of data are\nproduced every day, there are still huge gaps in what developers are actually\nable to use. Accessibility concerns, regulatory issues and imbalanced datasets\ncan all keep experts from using data. This impedes progress in finance, health\ncare and other domains.\n\nGood synthetic data can fill these gaps. The SDV uses machine learning to\nanalyze data. Then, it creates fully synthetic datasets that mimic the original.\nAlthough the synthetic data is entirely machine generated, it maintains the\noriginal format and mathematical properties. This makes synthetic data\nversatile. It can completely replace the existing data in a workflow, or it can\nsupplement the data to enhance its utility. Already, our users have successfully\nused the SDV to augment datasets, test applications, remove bias and more.\n\nA History of the SDV\nOur story starts in 2013. In MIT's Laboratory for Information and Decision\nSystems (LIDS), we were working on general data science projects. We had\ndeveloped new techniques, and we were excited to test them on real datasets.\nHowever, as soon as we asked for the data, we hit roadblocks. The process for\ngetting access to data turned out to be much more complex than we anticipated,\nwith many regulations and security red tape. \n\nWe wondered: What if we didn't need the real data in the first place? If we had\nsynthetic data with the same mathematical properties as the original, it would\nbe much easier for everyone to share and use.\n\nIn 2016, we released a paper describing the very first iteration of the SDV\n[https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf]. It introduced a\nnovel technique for synthesizing multi-table data, and included trials where\ndata scientists successfully used synthetic data instead of real data for\nmachine learning tasks. Related research to come out of the lab included CTGAN\n[https://arxiv.org/pdf/1907.00503.pdf], a novel approach to generating synthetic\ndata using deep learning.\n\nAfter these successes in the research community, we decided to move beyond\npurely academic solutions. Synthetic data has the potential to solve real-world\nproblems faced by people on all sides of data science: internal developers\nwriting software, external contractors working offshore, 3rd party partners\noffering services and even the end users who create the data. After some pilot\ntesting on enterprise applications, we open sourced our work in 2018, publishing \nsdv on PyPi [https://pypi.org/project/sdv/] for general use. Open sourcing\noffered ample opportunities for collaboration and customization. It allowed\nusers all over the world to test the SDV in enterprise settings, and helped the\nSDV ecosystem evolve into a one-stop shop for synthetic data needs!\n\nUsers all over the world are using our software to create synthetic data. This\nmap shows the total downloads* of CTGAN [https://github.com/sdv-dev/CTGAN] (our\nmost popular synthetic data model) per continent.We listened to feedback and, as\nof today, have made 93 releases (across all our libraries), addressing 504\nissues. We have been thrilled to see a burgeoning community of invested users\nusing the SDV to solve problems. We've seen over 200K user downloads from PyPi,\n400 stars in the SDV GitHub repository [https://github.com/sdv-dev/SDV] and 200\ndevelopers in our Slack channel. Our community is global and includes people in\ndiverse roles: academics, data scientists, operations managers, engineers and\nmore. We are continually learning from our community, and we're excited to bring\nnew innovations to you!\n\nJust the Beginning\nSynthetic data has the potential to revolutionize the entire field of data\nscience, allowing us to solve problems that once seemed untouchable. We want the\nSynthetic Data Vault to be the most trusted, transparent and comprehensive\nplatform for synthetic data generation, but we can't do it without our users.\nIt's our ever-growing open source community that allows us to quickly repair\nbugs, triage feature requests and improve to serve a variety of real-world\nneeds.\n\nThat’s where you come in. If you’re already a member of this community, we can’t\nthank you enough. And if you’d like to get involved, see below for ways to get\nstarted. Either way, watch this space for more nuanced discussions about\nsynthetic data. We're excited to share what we've learned from you, and show how\nwe are collectively improving the ecosystem. It’s time to open the vault!\n\nWant more ways to get involved?\n\n * Follow us on Twitter @sdv_dev [https://twitter.com/sdv_dev] for release\n   announcements, blog updates and more\n * Join our Slack\n   [https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw] \n   community to meet other users, discuss synthetic data solutions and suggest\n   topics for the blog\n * Visit & star our GitHub repositories [https://github.com/sdv-dev]\n * If you've successfully used the SDV for your project, share your experience\n   and tag us\n\nFor other inquiries, please contact us at info@sdv.dev.\n\n\n*Total download statistics per continent come from the Linehaul project\n[https://github.com/pypa/linehaul] using BigQuery, and include mirrors. Are you\naware of more accurate ways to count Python package downloads? Let us know!","html":"<p>Hello world! We, the creators of MIT's Synthetic Data Vault, warmly welcome you to our official blog. Soon we'll be using this space to deep-dive into topics related to our libraries, and to unpack ideas in the synthetic data space. We're looking forward to exploring this exciting area with you.</p><p>But first, we want to properly introduce our project: The <a href=\"https://github.com/sdv-dev/SDV\">Synthetic Data Vault</a> (SDV), an open source software ecosystem for generating synthetic data. In this post, we’ll explain why synthetic data is important, and tell the story of how we created the vault. We’ll also lay out what’s in store — and how you can get involved. Let’s get started with a brief overview.</p><h3 id=\"synthetic-data-what\">Synthetic Data What?</h3><p>Synthetic data is a bold new frontier in machine learning. It allows developers to share and use data more effectively.</p><p>It may seem counterintuitive, but although billions of gigabytes of data are produced every day, there are still huge gaps in what developers are actually able to use. Accessibility concerns, regulatory issues and imbalanced datasets can all keep experts from using data. This impedes progress in finance, health care and other domains.</p><p>Good synthetic data can fill these gaps. The SDV uses machine learning to analyze data. Then, it creates fully synthetic datasets that mimic the original. Although the synthetic data is entirely machine generated, it maintains the original format and mathematical properties. This makes synthetic data versatile. It can completely replace the existing data in a workflow, or it can supplement the data to enhance its utility. Already, our users have successfully used the SDV to augment datasets, test applications, remove bias and more.</p><h3 id=\"a-history-of-the-sdv\">A History of the SDV</h3><p>Our story starts in 2013. In MIT's Laboratory for Information and Decision Systems (LIDS), we were working on general data science projects. We had developed new techniques, and we were excited to test them on real datasets. However, as soon as we asked for the data, we hit roadblocks. The process for getting access to data turned out to be much more complex than we anticipated, with many regulations and security red tape. </p><p>We wondered: What if we didn't need the real data in the first place? If we had synthetic data with the same mathematical properties as the original, it would be much easier for everyone to share and use.</p><p>In 2016, we released a paper describing the very first iteration of the <a href=\"https://dai.lids.mit.edu/wp-content/uploads/2018/03/SDV.pdf\">SDV</a>. It introduced a novel technique for synthesizing multi-table data, and included trials where data scientists successfully used synthetic data instead of real data for machine learning tasks. Related research to come out of the lab included <a href=\"https://arxiv.org/pdf/1907.00503.pdf\">CTGAN</a>, a novel approach to generating synthetic data using deep learning.</p><p>After these successes in the research community, we decided to move beyond purely academic solutions. Synthetic data has the potential to solve real-world problems faced by people on all sides of data science: internal developers writing software, external contractors working offshore, 3rd party partners offering services and even the end users who create the data. After some pilot testing on enterprise applications, we open sourced our work in 2018, publishing <a href=\"https://pypi.org/project/sdv/\">sdv on PyPi</a> for general use. Open sourcing offered ample opportunities for collaboration and customization. It allowed users all over the world to test the SDV in enterprise settings, and helped the SDV ecosystem evolve into a one-stop shop for synthetic data needs!</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://sdv.ghost.io/content/images/2021/04/Blog-Map.png\" class=\"kg-image\" alt=\"A world map with download statistics from different continents.\" loading=\"lazy\" width=\"2000\" height=\"1279\" srcset=\"https://sdv.ghost.io/content/images/size/w600/2021/04/Blog-Map.png 600w, https://sdv.ghost.io/content/images/size/w1000/2021/04/Blog-Map.png 1000w, https://sdv.ghost.io/content/images/size/w1600/2021/04/Blog-Map.png 1600w, https://sdv.ghost.io/content/images/size/w2400/2021/04/Blog-Map.png 2400w\" sizes=\"(min-width: 720px) 720px\"><figcaption>Users all over the world are using our software to create synthetic data. This map shows the total downloads* of <a href=\"https://github.com/sdv-dev/CTGAN\">CTGAN</a> (our most popular synthetic data model) per continent.</figcaption></figure><p>We listened to feedback and, as of today, have made 93 releases (across all our libraries), addressing 504 issues. We have been thrilled to see a burgeoning community of invested users using the SDV to solve problems. We've seen over 200K user downloads from PyPi, 400 stars in the SDV <a href=\"https://github.com/sdv-dev/SDV\">GitHub repository</a> and 200 developers in our Slack channel. Our community is global and includes people in diverse roles: academics, data scientists, operations managers, engineers and more. We are continually learning from our community, and we're excited to bring new innovations to you!</p><h3 id=\"just-the-beginning\">Just the Beginning</h3><p>Synthetic data has the potential to revolutionize the entire field of data science, allowing us to solve problems that once seemed untouchable. We want the Synthetic Data Vault to be the most trusted, transparent and comprehensive platform for synthetic data generation, but we can't do it without our users. It's our ever-growing open source community that allows us to quickly repair bugs, triage feature requests and improve to serve a variety of real-world needs.  </p><p>That’s where you come in. If you’re already a member of this community, we can’t thank you enough. And if you’d like to get involved, see below for ways to get started. Either way, watch this space for more nuanced discussions about synthetic data. We're excited to share what we've learned from you, and show how we are collectively improving the ecosystem. It’s time to open the vault!</p><p><strong>Want more ways to get involved?</strong></p><ul><li>Follow us on Twitter <a href=\"https://twitter.com/sdv_dev\">@sdv_dev</a> for release announcements, blog updates and more</li><li>Join our <a href=\"https://join.slack.com/t/sdv-space/shared_invite/zt-gdsfcb5w-0QQpFMVoyB2Yd6SRiMplcw\">Slack</a> community to meet other users, discuss synthetic data solutions and suggest topics for the blog</li><li>Visit &amp; star our <a href=\"https://github.com/sdv-dev\">GitHub repositories</a></li><li>If you've successfully used the SDV for your project, share your experience and tag us</li></ul><p>For other inquiries, please contact us at <em><strong>info@sdv.dev</strong></em>.<br></p><p><em>*Total download statistics per continent come from the </em><a href=\"https://github.com/pypa/linehaul\"><em>Linehaul project</em></a><em> using BigQuery, and include mirrors. Are you aware of more accurate ways to count Python package downloads? Let us know!</em></p>","url":"https://sdv.ghost.io/intro-to-sdv/","canonical_url":null,"uuid":"13e75b5b-86d2-49b0-8940-b8e2861ea952","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"608c5562f9741d003b6f73b8","reading_time":4}}]}},"pageContext":{"slug":"neha","pageNumber":0,"humanPageNumber":1,"skip":0,"limit":12,"numberOfPages":1,"previousPagePath":"","nextPagePath":""}},"staticQueryHashes":["2061773391","2358152166","2362887240","2439066133","2561578252","2657115718","2731221146","2839364760","4145280475"]}